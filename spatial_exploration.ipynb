{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import shapely\n",
    "from shapely.geometry import MultiPolygon,Polygon\n",
    "from tueplots import bundles\n",
    "import contextily as cx\n",
    "from src.PlotFuncitons import *\n",
    "from src.DataLoaders import LKS01\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # does not affect other users\n",
    "# or consider setting your dpi in rcParams to a reasonably high value (also important for exporting if not explicitly given)\n",
    "\n",
    "'''\n",
    "# add lightness to colormap\n",
    "lightness = .8\n",
    "my_cmap = plt.cm.Oranges(np.arange(plt.cm.Oranges.N))\n",
    "my_cmap[:,0:3] *= lightness\n",
    "my_cmap[:,0:3] += (1-lightness)\n",
    "my_cmap = np.flip(my_cmap,0)\n",
    "my_cmap = ListedColormap(my_cmap)\n",
    "'''\n",
    "my_cmap = 'Oranges'\n",
    "ax_labels = {'ylabel':\"Northing (meter)\",\n",
    "          'xlabel':\"Easting (meter)\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plz_shape_df = gpd.read_file('Datasets/PLZ/plz-5stellig/plz-5stellig.shp', dtype={'plz': str}).to_crs(epsg=3857)\n",
    "plz_shape_df.drop(['einwohner','qkm'],axis=1,inplace=True)\n",
    "plz_shape_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plz_region_df = pd.read_csv('Datasets/PLZ/zuordnung_plz_ort.csv',sep=',',dtype={'plz': str})\n",
    "plz_region_df.drop(['osm_id','ags','landkreis'], axis=1, inplace=True)\n",
    "plz_region_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data.\n",
    "germany_df = pd.merge(\n",
    "    left=plz_shape_df, \n",
    "    right=plz_region_df, \n",
    "    on='plz',\n",
    "    how='inner'\n",
    ")\n",
    "germany_df.drop(['note'], axis=1, inplace=True)\n",
    "germany_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(bundles.icml2022(column='full',usetex=False))\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "germany_df.plot(\n",
    "    ax=ax, \n",
    "    column='bundesland', \n",
    "    categorical=True, \n",
    "    legend=True, \n",
    "    legend_kwds={'title':'Bundesland','bbox_to_anchor': (1.5,.8)},\n",
    "    cmap='tab20',\n",
    "    alpha=.9\n",
    ")\n",
    "plot_cities(ax)\n",
    "ax.set(title='Germany - Federal States',**ax_labels)\n",
    "cx.add_basemap(ax, source=cx.providers.Esri.WorldPhysical , zoom=6, attribution=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plz_einwohner_df = pd.read_csv(\n",
    "    'Datasets/PLZ/plz_einwohner.csv', \n",
    "    sep=',', \n",
    "    dtype={'plz': str, 'einwohner': int}\n",
    ")\n",
    "plz_einwohner_df.drop(['note','qkm','lat','lon'],axis=1,inplace=True)\n",
    "# Merge geo and inhabitant data\n",
    "germany_df = pd.merge(\n",
    "    left=germany_df, \n",
    "    right=plz_einwohner_df, \n",
    "    on='plz',\n",
    "    how='left'\n",
    ")\n",
    "germany_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot continuous distribution of inhabitants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(bundles.icml2022(column='full',usetex=False))\n",
    "fig, ax = plt.subplots()\n",
    "germany_df.plot(\n",
    "    ax=ax, \n",
    "    column='einwohner', \n",
    "    categorical=False, \n",
    "    legend=True, \n",
    "    cmap=my_cmap\n",
    "    )\n",
    "plot_cities(ax)\n",
    "ax.set(title='Germany: Number of Inhabitants per Postal Code',**ax_labels)\n",
    "cx.add_basemap(ax, source=cx.providers.Esri.WorldPhysical , zoom=6, attribution=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot discrete distribution in line with PKS \"Tatortverteilung\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 20000, 100000, 500000, float('inf')]\n",
    "labels = ['0-20k', '20k-100k', '100k-500k', '> 500k']\n",
    "germany_df['einwohner_kategorie'] = pd.cut(germany_df['einwohner'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "plt.rcParams.update(bundles.icml2022(column='full',usetex=False))\n",
    "fig, ax = plt.subplots()\n",
    "germany_df.plot(\n",
    "    ax=ax, \n",
    "    column='einwohner_kategorie', \n",
    "    legend=True, \n",
    "    cmap=my_cmap\n",
    ")\n",
    "plot_cities(ax)  \n",
    "ax.set(title='Germany: Number of Inhabitants per Postal Code',**ax_labels)\n",
    "cx.add_basemap(ax, source=cx.providers.Esri.WorldPhysical , zoom=6, attribution=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not the distribution we are looking for. Larger cities should have >500k inhabitants. Let's try grouping by postal codes instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = gpd.read_file('Datasets/PLZ/plz-5stellig/plz-5stellig.shp', dtype={'plz': str}).to_crs(epsg=3857)\n",
    "plz_map = pd.read_csv('Datasets/PLZ/georef-germany-postleitzahl.csv',sep=';',dtype={'Postleitzahl / Post code':str})\n",
    "plz_map = plz_map.rename(columns={'Postleitzahl / Post code':'plz'})\n",
    "merged_df = pd.merge(geo_df, plz_map, on='plz',how='left')\n",
    "merged_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = merged_df.groupby('PLZ Name (short)').agg({\n",
    "    'geometry': lambda x: MultiPolygon([geom if isinstance(geom, Polygon) else geom.geoms for geom in x]),\n",
    "    'einwohner': 'sum'\n",
    "}).reset_index()\n",
    "grouped_gdf = gpd.GeoDataFrame(grouped_df, geometry='geometry')\n",
    "\n",
    "grouped_gdf['einwohner_kategorie'] = pd.cut(grouped_gdf['einwohner'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "bins = [0, 20000, 100000, 500000, float('inf')]\n",
    "labels = ['0-20k', '20k-100k', '100k-500k', '> 500k']\n",
    "\n",
    "plt.rcParams.update(bundles.icml2022(column='full',usetex=False))\n",
    "fig, ax = plt.subplots()\n",
    "grouped_gdf.plot(ax=ax,column='einwohner_kategorie', legend=True,cmap=my_cmap)\n",
    "plot_cities(ax)\n",
    "ax.set(title='Germany: Number of Inhabitants per Postal Code',**ax_labels)\n",
    "cx.add_basemap(ax, source=cx.providers.Esri.WorldPhysical , zoom=6, attribution=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking better, but we are missing quite a lot of data. Let's switch to a another geodataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = gpd.read_file('Datasets/PLZ/georef-germany-postleitzahl/georef-germany-postleitzahl.shp').to_crs(epsg=3857)\n",
    "geo_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update(bundles.icml2022(column='full',usetex=False))\n",
    "fig,ax = plt.subplots()\n",
    "geo_df.plot(\n",
    "    ax=ax, \n",
    "    column='lan_code', \n",
    "    categorical=True, \n",
    "    legend=True, \n",
    "    legend_kwds={'title':'First Digit', 'bbox_to_anchor': (1.25,.8)},\n",
    "    cmap='tab20',\n",
    "    alpha=.9\n",
    ")\n",
    "plot_cities(ax)\n",
    "ax.set(title='Germany',**ax_labels)\n",
    "cx.add_basemap(ax, source=cx.providers.Esri.WorldPhysical , zoom=6, attribution=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Darker regions show some overlap in the regions, but overall not too bad. Merge it with inhabitants on postal codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhabitans_df = pd.read_csv('Datasets/PLZ/plz_einwohner.csv',dtype={'plz':str}).rename(columns={'plz':'plz_code'})\n",
    "merged_df = pd.merge(geo_df,inhabitans_df,on='plz_code',how='left')\n",
    "merged_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try grouping inhabitants by \"Kreis\" codes this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = merged_df.groupby('krs_code').agg({\n",
    "    'geometry': lambda x: MultiPolygon([geom if isinstance(geom, Polygon) else geom.geoms for geom in x]),\n",
    "    'einwohner': 'sum'\n",
    "}).reset_index()\n",
    "grouped_gdf = gpd.GeoDataFrame(grouped_df, geometry='geometry')\n",
    "bins = [0, 20000, 100000, 500000, float('inf')]\n",
    "labels = ['0-20k', '20k-100k', '100k-500k', '> 500k']\n",
    "grouped_gdf['einwohner_kategorie'] = pd.cut(grouped_gdf['einwohner'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "plt.rcParams.update(bundles.icml2022(column='full',usetex=False))\n",
    "fig, ax = plt.subplots()\n",
    "grouped_gdf.plot(ax=ax,column='einwohner_kategorie', legend=True,cmap=my_cmap)\n",
    "plot_cities(ax)\n",
    "ax.set(title=\"Germany: Number of Inhabitants per 'Kreis' Code\",**ax_labels)\n",
    "cx.add_basemap(ax, source=cx.providers.Esri.WorldPhysical , zoom=6, attribution=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Granularity is too low this time as we are not seeing any regions with <20k inhabitants. Try postal code names as last resort..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = merged_df.groupby('plz_name').agg({\n",
    "    'geometry': lambda x: MultiPolygon([geom if isinstance(geom, Polygon) else geom.geoms for geom in x]),\n",
    "    'einwohner': 'sum'\n",
    "}).reset_index()\n",
    "grouped_gdf = gpd.GeoDataFrame(grouped_df, geometry='geometry')\n",
    "bins = [0, 20000, 100000, 500000, float('inf')]\n",
    "labels = ['0-20k', '20k-100k', '100k-500k', '> 500k']\n",
    "grouped_gdf['einwohner_kategorie'] = pd.cut(grouped_gdf['einwohner'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "plt.rcParams.update(bundles.icml2022(column='full',usetex=False))\n",
    "fig, ax = plt.subplots()\n",
    "grouped_gdf.plot(ax=ax,column='einwohner_kategorie', legend=True,cmap=my_cmap)\n",
    "plot_cities(ax)\n",
    "ax.set(title=\"Germany: Number of Inhabitants per Postal Code Name\",**ax_labels)\n",
    "cx.add_basemap(ax, source=cx.providers.Esri.WorldPhysical , zoom=6, attribution=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks reasonable. However, we can verify that this is not the exact binning used by the BKA by looking at the data from Berlin:\n",
    "\n",
    "Here we have all the cases in the >500k category and none in the lower bins, but our plot still splits Berlin into many smaller parts with <500k inhabitants. While this is the most obvious issue, we have no way automatically checking for more problems as there is no detailed explanation in the PKS tables as to what exactly is considered a \"region\". *\n",
    "\n",
    "* BIK regions might be possible, however that data is not publicly available (perhaps on request)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rest....\n",
    "\n",
    "\n",
    "Load crime data\n",
    "\n",
    "clean existing geo data\n",
    "\n",
    "reduce to federal states since we have spatial distribution of crimes for that as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce GeoData to Federal States\n",
    "\n",
    "Problems:\n",
    "- merging GeoDataFrame on federal states leaves noisy borders (solve by shrinking and expanding with buffer; only slight loss of precision)\n",
    "- federal states in this dataset are not free of overlaps and show up in plots (solve by manually checking maps and removing overlap from the state that is too large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = gpd.read_file('Datasets/PLZ/georef-germany-postleitzahl/georef-germany-postleitzahl.shp')\n",
    "geo_df.rename(columns={'lan_name':'Bundesland'},inplace=True)\n",
    "bu_geo_full = geo_df.groupby('Bundesland').agg({\n",
    "    'geometry': lambda x: MultiPolygon([geom if isinstance(geom, Polygon) else geom.geoms for geom in x])\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "# reduce geo information to outline of states\n",
    "bu_geo_reduced = bu_geo_full.copy()\n",
    "bu_geo_reduced['geometry'] = bu_geo_full['geometry'].apply(lambda x: shapely.ops.unary_union(x))\n",
    "\n",
    "# re-compute shapes with slight buffering to avoid holes where borders don't line up perfectly\n",
    "bu_geo_smooth = bu_geo_reduced.copy()\n",
    "bu_geo_smooth['geometry'] = bu_geo_reduced['geometry'].apply(\n",
    "    lambda x: x.buffer(1e-5, 1, join_style=shapely.geometry.JOIN_STYLE.mitre).buffer(-1e-4, 1, join_style=shapely.geometry.JOIN_STYLE.mitre))\n",
    "\n",
    "bu_geo_full = gpd.GeoDataFrame(bu_geo_full,geometry='geometry',crs='EPSG:4326').to_crs(epsg=3857)\n",
    "bu_geo_reduced = gpd.GeoDataFrame(bu_geo_reduced,geometry='geometry',crs='EPSG:4326').to_crs(epsg=3857)\n",
    "bu_geo_smooth = gpd.GeoDataFrame(bu_geo_smooth,geometry='geometry',crs='EPSG:4326').to_crs(epsg=3857)\n",
    "\n",
    "overlaps = {'BU_1':[],'BU_2':[],'geometry':[]}\n",
    "for _,bu1 in bu_geo_smooth.iterrows(): \n",
    "    for _,bu2 in bu_geo_smooth.iterrows():\n",
    "        if bu1['Bundesland'] != bu2['Bundesland']:\n",
    "            overlaps['BU_1'].append(bu1['Bundesland'])\n",
    "            overlaps['BU_2'].append(bu2['Bundesland'])\n",
    "            overlaps['geometry'].append(bu1.geometry.intersection(bu2.geometry))\n",
    "overlaps = gpd.GeoDataFrame(overlaps,geometry='geometry')\n",
    "overlaps = overlaps[~overlaps['geometry'].is_empty].reset_index(drop=True) # drop empty intersections\n",
    "\n",
    "plt.rcParams.update(bundles.icml2022(column='full',usetex=False))\n",
    "fig,axs = plt.subplots(1,3,sharex=True,sharey=True,layout='tight')\n",
    "bu_geo_full.plot(ax=axs[0],alpha=.5,edgecolor='black',linewidth=.5)\n",
    "axs[0].set(title='All regions')\n",
    "bu_geo_reduced.plot(ax=axs[1],alpha=.5,edgecolor='black',linewidth=.5)\n",
    "axs[1].set(title='Grouped by federal state')\n",
    "bu_geo_smooth.plot(ax=axs[2],alpha=.5,edgecolor='black',linewidth=.5)\n",
    "overlaps.plot(ax=axs[2],facecolor='red',edgecolor='none')\n",
    "axs[2].set(title='Overlapping regions after smoothing')\n",
    "fig.supxlabel('Easting (meter)')\n",
    "fig.supylabel('Northing (meter)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = bu_geo_smooth.copy()\n",
    "\n",
    "def remove_intersection(region1, region2):\n",
    "    '''Removes the intersecting region from region 1\n",
    "\n",
    "    Input:\n",
    "    :param: region1: The region which is too large\n",
    "    :param: region2: The region which the area actally belongs to\n",
    "    \n",
    "    Output:\n",
    "    :return: Reduced shape of region 1\n",
    "    '''\n",
    "    reduced = []\n",
    "    for pol1 in region1:\n",
    "        for pol2 in region2:\n",
    "            if pol1.intersects(pol2):\n",
    "                # If they intersect, create a new polygon that is\n",
    "                # essentially pol1 minus the intersection\n",
    "                nonoverlap = (pol1.symmetric_difference(pol2)).difference(pol2)\n",
    "                reduced.append(list(nonoverlap.geoms) if isinstance(nonoverlap,MultiPolygon) else nonoverlap)\n",
    "            else:\n",
    "                # Otherwise, just keep the initial polygon as it is.\n",
    "                reduced.append(pol1)\n",
    "    return shapely.ops.unary_union(reduced)\n",
    "\n",
    "\n",
    "def cleanBU_(df,bu1,bu2):\n",
    "    df.loc[df.loc[:,\"Bundesland\"] == bu1,\"geometry\"] = remove_intersection(\n",
    "        df.loc[df.loc[:,\"Bundesland\"] == bu1,\"geometry\"],\n",
    "        df.loc[df.loc[:,\"Bundesland\"] == bu2,\"geometry\"])\n",
    "\n",
    "\n",
    "cleanBU_(geo,\"Hessen\",\"Niedersachsen\")\n",
    "cleanBU_(geo,\"Hessen\",\"Rheinland-Pfalz\")\n",
    "cleanBU_(geo,\"Hessen\",\"Nordrhein-Westfalen\")\n",
    "cleanBU_(geo,\"Bayern\",\"Baden-Württemberg\")\n",
    "cleanBU_(geo,\"Baden-Württemberg\",\"Hessen\")\n",
    "cleanBU_(geo,\"Thüringen\",\"Sachsen\")\n",
    "cleanBU_(geo,\"Schleswig-Holstein\",\"Hamburg\")\n",
    "cleanBU_(geo,\"Mecklenburg-Vorpommern\",\"Niedersachsen\")\n",
    "cleanBU_(geo,\"Mecklenburg-Vorpommern\",\"Brandenburg\")\n",
    "cleanBU_(geo,\"Sachsen-Anhalt\",\"Brandenburg\")\n",
    "\n",
    "plt.rcParams.update(bundles.icml2022(column='full',usetex=False))\n",
    "ax = geo.plot(alpha=0.7,edgecolor='black',linewidth=.5,facecolor='orange')\n",
    "ax.set(title='Overlap-free geo data',**ax_labels)\n",
    "cx.add_basemap(ax, source=cx.providers.Esri.WorldPhysical , zoom=6, attribution=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = LKS01()\n",
    "cases = data[2022].loc[data[2022]['Schlüssel'] == '------']\n",
    "merged_df = pd.merge(cases,geo,on='Bundesland')\n",
    "merged_df = gpd.GeoDataFrame(merged_df, geometry='geometry')\n",
    "\n",
    "plt.rcParams.update(bundles.icml2022(column='full',usetex=False))\n",
    "fig, ax = plt.subplots()\n",
    "merged_df.plot(ax=ax,\n",
    "               column='Anzahl erfasste Fälle',\n",
    "               legend=True,\n",
    "               cmap=my_cmap,\n",
    "               legend_kwds={'label':'Absolute number of crimes'},\n",
    "               edgecolor='black',\n",
    "               linewidth=.1)\n",
    "plot_cities(ax)\n",
    "ax.set(title=\"Germany 2022: Crimes per federal state\",**ax_labels)\n",
    "cx.add_basemap(ax, source=cx.providers.Esri.WorldPhysical , zoom=6, attribution=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cybercrime per federal state over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = []\n",
    "# no \"%-Anteil an allen Fällen\" column available before 2019; compute it manually:\n",
    "print('Loading 2013 - 2022 ...')\n",
    "for year in range(2013,2019):\n",
    "    print(f'Year: {year}', end=\"\\r\", flush=True)\n",
    "    df_year = data[year]\n",
    "    df_year_all = df_year[df_year['Schlüssel'] == '------']['Anzahl erfasste Fälle'].to_numpy()\n",
    "    df_year = df_year.loc[df_year['Schlüssel'] == '897000']\n",
    "    df_year['%-Anteil an allen Fällen'] = df_year['Anzahl erfasste Fälle'].to_numpy() / df_year_all * 100\n",
    "    merged_year = pd.merge(df_year,geo,on='Bundesland')\n",
    "    merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))\n",
    "for year in range(2019,2023):\n",
    "    print(f'Year: {year}', end=\"\\r\", flush=True)\n",
    "    df_year = data[year]\n",
    "    df_year = df_year.loc[df_year['Schlüssel'] == '897000']\n",
    "    merged_year = pd.merge(df_year,geo,on='Bundesland')\n",
    "    merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = min([x['%-Anteil an allen Fällen'].min() for x in merged_data])\n",
    "vmax = max([x['%-Anteil an allen Fällen'].max() for x in merged_data])\n",
    "\n",
    "fig, axs = plt.subplots(3,4,layout='constrained',figsize=(8,7))\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "    if i < len(merged_data):\n",
    "        merged_data[i].plot(ax=ax,\n",
    "                            column='%-Anteil an allen Fällen',\n",
    "                            legend=False,\n",
    "                            cmap=my_cmap,\n",
    "                            vmin=vmin,\n",
    "                            vmax=vmax,\n",
    "                            edgecolor='black',\n",
    "                            linewidth=.1)\n",
    "        ax.set(title=i+2013)\n",
    "    ax.set_axis_off()\n",
    "    if i == len(merged_data):\n",
    "        plot_cbar(ax,vmin,vmax,my_cmap,'% of all crime')\n",
    "fig.suptitle(\"Germany: Cybercrime per federal state (relative)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh? Shouldn't 2020 and 2021 be overall higher than other years? (see temporal analysis)\n",
    "\n",
    "Problem: For some reason the fraction of all crime in 2020 and 2021 is not computed wrt. the number of crimes in each federal state, but in all of Germany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fraction(df_year):\n",
    "    df_year_all = df_year[df_year['Schlüssel'] == '------']['Anzahl erfasste Fälle'].to_numpy()\n",
    "    df_year = df_year.loc[df_year['Schlüssel'] == '897000'].copy()\n",
    "    if '%-Anteil an allen Fällen' in df_year.columns:\n",
    "        df_year.loc[:,'%-Anteil an allen Fällen'] = df_year['Anzahl erfasste Fälle'].to_numpy() / df_year_all * 100\n",
    "    else:\n",
    "       df_year['%-Anteil an allen Fällen'] = df_year['Anzahl erfasste Fälle'].to_numpy() / df_year_all * 100\n",
    "    return pd.merge(df_year,geo,on='Bundesland')\n",
    "\n",
    "merged_data = []\n",
    "# no \"%-Anteil an allen Fällen\" column available before 2019; compute it manually and fix 2020,2021:\n",
    "print('Loading 2013 - 2022 ...')\n",
    "for year in range(2013,2023):\n",
    "    print(f'Year: {year}', end=\"\\r\", flush=True)\n",
    "    df_year = data[year]\n",
    "    if year in [2019,2022]:\n",
    "        df_year = df_year.loc[df_year['Schlüssel'] == '897000']\n",
    "        merged_year = pd.merge(df_year,geo,on='Bundesland')\n",
    "        merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))\n",
    "    else:\n",
    "        merged_year = add_fraction(df_year)\n",
    "        merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = min([x['%-Anteil an allen Fällen'].min() for x in merged_data])\n",
    "vmax = max([x['%-Anteil an allen Fällen'].max() for x in merged_data])\n",
    "\n",
    "fig, axs = plt.subplots(3,4,layout='constrained',figsize=(8,7))\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "    if i < len(merged_data):\n",
    "        im = merged_data[i].plot(ax=ax,\n",
    "                            column='%-Anteil an allen Fällen',\n",
    "                            legend=False,\n",
    "                            cmap=my_cmap,\n",
    "                            vmin=vmin,\n",
    "                            vmax=vmax,\n",
    "                            edgecolor='black',\n",
    "                            linewidth=.1)\n",
    "        ax.set(title=i+2013)\n",
    "    ax.set_axis_off()\n",
    "    if i == len(merged_data):\n",
    "        plot_cbar(ax,vmin,vmax,my_cmap,'% of all crime')\n",
    "fig.suptitle(\"Germany: Cybercrime per federal state (relative)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fraud\n",
    "Summenschlüssel:\n",
    "\n",
    "510000: Betrug §§ 263, 263a, 264, 264a, 265, 265a-e StGB\n",
    "\n",
    "897100: Computerbetrug § 263a StGB\n",
    "\n",
    "\"Analog\" = 51000 - 897100\n",
    "\n",
    "\"Digital\" = 897100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data = []\n",
    "# sumkey 897100 did not exist before 2016 (maybe also an explanation why we see sudden increase in cybercrime for that year)\n",
    "print('Loading 2016 - 2022 ...')\n",
    "for year in range(2016,2023):\n",
    "    print(f'Year: {year}', end=\"\\r\", flush=True)\n",
    "    df_year = data[year]\n",
    "    df_year_fraud = df_year.loc[df_year['Schlüssel'] == '510000']\n",
    "    df_year_cfraud = df_year.loc[df_year['Schlüssel'] == '897100']\n",
    "    df_year_ratio = pd.DataFrame({'Bundesland':df_year_fraud['Bundesland'],\n",
    "                                  'Anteil':np.array(df_year_cfraud['Anzahl erfasste Fälle']) /\n",
    "                                  (np.array(df_year_fraud['Anzahl erfasste Fälle']) - np.array(df_year_cfraud['Anzahl erfasste Fälle'])) * 100})\n",
    "    merged_year = pd.merge(df_year_ratio,geo,on='Bundesland')\n",
    "    merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = min([x['Anteil'].min() for x in merged_data])\n",
    "vmax = max([x['Anteil'].max() for x in merged_data])\n",
    "\n",
    "fig, axs = plt.subplots(3,3,layout='constrained',figsize=(6,7))\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "    if i < len(merged_data):\n",
    "        merged_data[i].plot(ax=ax,\n",
    "                            column='Anteil',\n",
    "                            legend=False,\n",
    "                            cmap=my_cmap,\n",
    "                            vmin=vmin,\n",
    "                            vmax=vmax,\n",
    "                            edgecolor='black',\n",
    "                            linewidth=.1)\n",
    "        ax.set(title=i+2016)\n",
    "    ax.set_axis_off()\n",
    "    if i == len(merged_data):\n",
    "        plot_cbar(ax,vmin,vmax,my_cmap,'% of all fraud')\n",
    "fig.suptitle(\"Germany: Computer fraud\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get inhabitants per federalstate from #TODO: Destatis url\n",
    "inhabitants = np.array([11124642,\n",
    "                        13176989,\n",
    "                        3677472,\n",
    "                        2537868,\n",
    "                        676463,\n",
    "                        1853935,\n",
    "                        6295017,\n",
    "                        1611160,\n",
    "                        8027031,\n",
    "                        17924591,\n",
    "                        4106485,\n",
    "                        982348,\n",
    "                        4043002,\n",
    "                        2169253,\n",
    "                        2922005,\n",
    "                        2108863,\n",
    "                        84358845])\n",
    "\n",
    "merged_data = []\n",
    "print('Loading 2013 - 2022 ...')\n",
    "for year in range(2013,2019):\n",
    "    print(f'Year: {year}', end=\"\\r\", flush=True)\n",
    "    df_year = data[year]\n",
    "    cases = df_year.loc[df_year['Schlüssel'] == '------']\n",
    "    merged_year = pd.merge(cases,geo,on='Bundesland')\n",
    "    merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))\n",
    "for year in range(2019,2023):\n",
    "    print(f'Year: {year}', end=\"\\r\", flush=True)\n",
    "    df_year = data[year]\n",
    "    cases = df_year.loc[df_year['Schlüssel'] == '------'].copy() # explicitly copying here takes way longer, but gets rid of the warnings...\n",
    "    cases['HZ nach Zensus'] = cases['Anzahl erfasste Fälle'].to_numpy() / inhabitants * 1e5 # scale to 100,000\n",
    "    merged_year = pd.merge(cases,geo,on='Bundesland')\n",
    "    merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = min([x['HZ nach Zensus'].min() for x in merged_data])\n",
    "vmax = max([x['HZ nach Zensus'].max() for x in merged_data])\n",
    "\n",
    "fig, axs = plt.subplots(3,4,layout='constrained',figsize=(8,7))\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "    if i < len(merged_data):\n",
    "        merged_data[i].plot(ax=ax,\n",
    "                            column='HZ nach Zensus',\n",
    "                            legend=False,\n",
    "                            cmap=my_cmap,\n",
    "                            vmin=vmin,\n",
    "                            vmax=vmax,\n",
    "                            edgecolor='black',\n",
    "                            linewidth=.1)\n",
    "        ax.set(title=i+2013)\n",
    "    ax.set_axis_off()\n",
    "    if i == len(merged_data):\n",
    "        plot_cbar(ax,vmin,vmax,my_cmap)\n",
    "fig.suptitle(\"Germany: Crimes per Capita and Federal State\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation of digital crime rates to population density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get area from each federal state in km^2\n",
    "# source: https://en.wikipedia.org/wiki/States_of_Germany#List\n",
    "area = [35752,\n",
    "        70552,\n",
    "        892,\n",
    "        29480,\n",
    "        419,\n",
    "        755,\n",
    "        21115,\n",
    "        23180,\n",
    "        47609,\n",
    "        34085,\n",
    "        19853,\n",
    "        2569,\n",
    "        18416,\n",
    "        20446,\n",
    "        15799,\n",
    "        16172,\n",
    "        357600]\n",
    "\n",
    "density = inhabitants / area\n",
    "\n",
    "density # inhabitants / km^2\n",
    "geo['Dichte'] = density[:-1] # drop germany\n",
    "\n",
    "\n",
    "plt.rcParams.update(bundles.icml2022(column='full',usetex=False))\n",
    "fig, ax = plt.subplots()\n",
    "geo.plot(ax=ax,\n",
    "               column='Dichte',\n",
    "               norm=mpl.colors.LogNorm(vmin=geo.Dichte.min(), vmax=1e4),\n",
    "               legend=True,\n",
    "               cmap=my_cmap,\n",
    "               legend_kwds={'label':'# inhabitants / km$^2$'},\n",
    "               edgecolor='black',\n",
    "               linewidth=.1)\n",
    "plot_cities(ax)\n",
    "ax.set(title=\"Germany: Inhabitant density\",**ax_labels)\n",
    "cx.add_basemap(ax, source=cx.providers.Esri.WorldPhysical , zoom=6, attribution=False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
