{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from shapely.geometry import MultiPolygon,Polygon\n",
    "import shapely\n",
    "from src.PlotFuncitons import *\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # does not affect other users\n",
    "# or consider setting your dpi in rcParams to a reasonably high value (also important for exporting if not explicitly given)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cooler Blog zu Mapping\n",
    "Folgendes ist aus dem Artikel:\n",
    "https://juanitorduz.github.io/germany_plots/\n",
    "\n",
    "Sein Skript geht noch weiter, allerdings ist das f체r uns nicht relevant. Falls in den sp채teren Zellen was nicht funktioniert wie erwartet: Alle Zellen ab hier nochmal laufen lassen. Viele Operationen sind mehr oder weniger offensichtlich inplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you read postal codes as strings, otherwise \n",
    "# the postal code 01110 will be parsed as the number 1110. \n",
    "plz_shape_df = gpd.read_file('Datasets/PLZ/plz-5stellig/plz-5stellig.shp', dtype={'plz': str}) # ,encoding='Windows-1252')\n",
    "plz_shape_df.drop(['einwohner','qkm'],axis=1,inplace=True)\n",
    "plz_shape_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [16, 11]\n",
    "\n",
    "# Get lat and lng of Germany's main cities. \n",
    "top_cities = {\n",
    "    'Berlin': (13.404954, 52.520008), \n",
    "    'Cologne': (6.953101, 50.935173),\n",
    "    'D체sseldorf': (6.782048, 51.227144),\n",
    "    'Frankfurt am Main': (8.682127, 50.110924),\n",
    "    'Hamburg': (9.993682, 53.551086),\n",
    "    'Leipzig': (12.387772, 51.343479),\n",
    "    'Munich': (11.576124, 48.137154),\n",
    "    'Dortmund': (7.468554, 51.513400),\n",
    "    'Stuttgart': (9.181332, 48.777128),\n",
    "    'Nuremberg': (11.077438, 49.449820),\n",
    "    'Hannover': (9.73322, 52.37052)\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plz_shape_df.plot(ax=ax, color='orange', alpha=0.8)\n",
    "\n",
    "# Plot cities. \n",
    "for c in top_cities.keys():\n",
    "    # Plot city name.\n",
    "    ax.text(\n",
    "        x=top_cities[c][0], \n",
    "        # Add small shift to avoid overlap with point.\n",
    "        y=top_cities[c][1] + 0.08, \n",
    "        s=c, \n",
    "        fontsize=12,\n",
    "        ha='center', \n",
    "    )\n",
    "    # Plot city location centroid.\n",
    "    ax.plot(\n",
    "        top_cities[c][0], \n",
    "        top_cities[c][1], \n",
    "        marker='o',\n",
    "        c='black', \n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "ax.set(\n",
    "    title='Germany', \n",
    "    aspect=1.4, \n",
    "    facecolor='lightblue'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature.\n",
    "plz_shape_df = plz_shape_df.assign(first_dig_plz = lambda x: x['plz'].str.slice(start=0, stop=1))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plz_shape_df.plot(\n",
    "    ax=ax, \n",
    "    column='first_dig_plz', \n",
    "    categorical=True, \n",
    "    legend=True, \n",
    "    legend_kwds={'title':'First Digit', 'loc':'lower right'},\n",
    "    cmap='tab20',\n",
    "    alpha=0.9\n",
    ")\n",
    "\n",
    "for c in top_cities.keys():\n",
    "\n",
    "    ax.text(\n",
    "        x=top_cities[c][0], \n",
    "        y=top_cities[c][1] + 0.08, \n",
    "        s=c, \n",
    "        fontsize=12,\n",
    "        ha='center', \n",
    "    )\n",
    "\n",
    "    ax.plot(\n",
    "        top_cities[c][0], \n",
    "        top_cities[c][1], \n",
    "        marker='o',\n",
    "        c='black', \n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "ax.set(\n",
    "    title='Germany First-Digit-Postal Codes Areas', \n",
    "    aspect=1.4,\n",
    "    facecolor='white'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plz_region_df = pd.read_csv(\n",
    "    'Datasets/PLZ/zuordnung_plz_ort.csv', \n",
    "    sep=',', \n",
    "    dtype={'plz': str}\n",
    ")\n",
    "\n",
    "plz_region_df.drop(['osm_id','ags','landkreis'], axis=1, inplace=True)\n",
    "\n",
    "plz_region_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data.\n",
    "germany_df = pd.merge(\n",
    "    left=plz_shape_df, \n",
    "    right=plz_region_df, \n",
    "    on='plz',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "germany_df.drop(['note'], axis=1, inplace=True)\n",
    "\n",
    "germany_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "germany_df.plot(\n",
    "    ax=ax, \n",
    "    column='bundesland', \n",
    "    categorical=True, \n",
    "    legend=True, \n",
    "    legend_kwds={'title':'Bundesland', 'bbox_to_anchor': (1.35, 0.8)},\n",
    "    cmap='tab20',\n",
    "    alpha=0.9\n",
    ")\n",
    "\n",
    "for c in top_cities.keys():\n",
    "\n",
    "    ax.text(\n",
    "        x=top_cities[c][0], \n",
    "        y=top_cities[c][1] + 0.08, \n",
    "        s=c, \n",
    "        fontsize=12,\n",
    "        ha='center', \n",
    "    )\n",
    "\n",
    "    ax.plot(\n",
    "        top_cities[c][0], \n",
    "        top_cities[c][1], \n",
    "        marker='o',\n",
    "        c='black', \n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "ax.set(\n",
    "    title='Germany - Bundesl채nder', \n",
    "    aspect=1.4, \n",
    "    facecolor='white'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plz_einwohner_df = pd.read_csv(\n",
    "    'Datasets/PLZ/plz_einwohner.csv', \n",
    "    sep=',', \n",
    "    dtype={'plz': str, 'einwohner': int}\n",
    ")\n",
    "plz_einwohner_df.drop(['note','qkm','lat','lon'],axis=1,inplace=True)\n",
    "plz_einwohner_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data.\n",
    "germany_df = pd.merge(\n",
    "    left=germany_df, \n",
    "    right=plz_einwohner_df, \n",
    "    on='plz',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "germany_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "germany_df.plot(\n",
    "    ax=ax, \n",
    "    column='einwohner', \n",
    "    categorical=False, \n",
    "    legend=True, \n",
    "    cmap='RdYlGn_r',\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "for c in top_cities.keys():\n",
    "\n",
    "    ax.text(\n",
    "        x=top_cities[c][0], \n",
    "        y=top_cities[c][1] + 0.08, \n",
    "        s=c, \n",
    "        fontsize=12,\n",
    "        ha='center', \n",
    "    )\n",
    "\n",
    "    ax.plot(\n",
    "        top_cities[c][0], \n",
    "        top_cities[c][1], \n",
    "        marker='o',\n",
    "        c='black', \n",
    "        alpha=0.5\n",
    "    )\n",
    "    \n",
    "ax.set(\n",
    "    title='Germany: Number of Inhabitants per Postal Code', \n",
    "    aspect=1.4, \n",
    "    facecolor='lightblue'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 20000, 100000, 500000, float('inf')]\n",
    "labels = ['0-20k', '20k-100k', '100k-500k', '> 500k']\n",
    "germany_df['einwohner_kategorie'] = pd.cut(germany_df['einwohner'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "germany_df.plot(\n",
    "    ax=ax, \n",
    "    column='einwohner_kategorie', \n",
    "    legend=True, \n",
    "    cmap='RdYlGn_r',\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "for c in top_cities.keys():\n",
    "\n",
    "    ax.text(\n",
    "        x=top_cities[c][0], \n",
    "        y=top_cities[c][1] + 0.08, \n",
    "        s=c, \n",
    "        fontsize=12,\n",
    "        ha='center', \n",
    "    )\n",
    "\n",
    "    ax.plot(\n",
    "        top_cities[c][0], \n",
    "        top_cities[c][1], \n",
    "        marker='o',\n",
    "        c='black', \n",
    "        alpha=0.5\n",
    "    )\n",
    "    \n",
    "ax.set(\n",
    "    title='Germany: Number of Inhabitants per Postal Code', \n",
    "    aspect=1.4, \n",
    "    facecolor='lightblue'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ab hier kommt wieder meine Code Ursuppe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = gpd.read_file('Datasets/PLZ/plz-5stellig/plz-5stellig.shp', dtype={'plz': str})\n",
    "plz_map = pd.read_csv('Datasets/PLZ/georef-germany-postleitzahl.csv',sep=';',dtype={'Postleitzahl / Post code':str})\n",
    "plz_map = plz_map.rename(columns={'Postleitzahl / Post code':'plz'})\n",
    "merged_df = pd.merge(geo_df, plz_map, on='plz',how='left')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = merged_df.groupby('PLZ Name (short)').agg({\n",
    "    'geometry': lambda x: MultiPolygon([geom if isinstance(geom, Polygon) else geom.geoms for geom in x]),\n",
    "    'einwohner': 'sum'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "grouped_gdf = gpd.GeoDataFrame(grouped_df, geometry='geometry')\n",
    "\n",
    "bins = [0, 20000, 100000, 500000, float('inf')]\n",
    "labels = ['0-20k', '20k-100k', '100k-500k', '> 500k']\n",
    "\n",
    "grouped_gdf['einwohner_kategorie'] = pd.cut(grouped_gdf['einwohner'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "grouped_gdf.plot(ax=ax,column='einwohner_kategorie', legend=True,cmap='RdYlGn_r')\n",
    "ax.set(\n",
    "    title='Germany: Number of Inhabitants per Postal Code', \n",
    "    aspect=1.3, \n",
    "    facecolor='lightblue'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = gpd.read_file('Datasets/PLZ/georef-germany-postleitzahl/georef-germany-postleitzahl.shp')\n",
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "geo_df.plot(\n",
    "    ax=ax, \n",
    "    column='lan_code', \n",
    "    categorical=True, \n",
    "    legend=True, \n",
    "    legend_kwds={'title':'First Digit', 'loc':'lower right'},\n",
    "    cmap='tab20',\n",
    "    alpha=.7\n",
    ")\n",
    "# Plot cities. \n",
    "for c in top_cities.keys():\n",
    "    # Plot city name.\n",
    "    ax.text(\n",
    "        x=top_cities[c][0], \n",
    "        # Add small shift to avoid overlap with point.\n",
    "        y=top_cities[c][1] + 0.08, \n",
    "        s=c, \n",
    "        fontsize=12,\n",
    "        ha='center', \n",
    "    )\n",
    "    # Plot city location centroid.\n",
    "    ax.plot(\n",
    "        top_cities[c][0], \n",
    "        top_cities[c][1], \n",
    "        marker='o',\n",
    "        c='black', \n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "ax.set(\n",
    "    title='Germany', \n",
    "    aspect=1.4, \n",
    "    facecolor='lightblue',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhabitans_df = pd.read_csv('Datasets/PLZ/plz_einwohner.csv',dtype={'plz':str}).rename(columns={'plz':'plz_code'})\n",
    "merged_df = pd.merge(geo_df,inhabitans_df,on='plz_code',how='left')\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = merged_df.groupby('krs_code').agg({\n",
    "    'geometry': lambda x: MultiPolygon([geom if isinstance(geom, Polygon) else geom.geoms for geom in x]),\n",
    "    'einwohner': 'sum'\n",
    "}).reset_index()\n",
    "grouped_gdf = gpd.GeoDataFrame(grouped_df, geometry='geometry')\n",
    "bins = [0, 20000, 100000, 500000, float('inf')]\n",
    "labels = ['0-20k', '20k-100k', '100k-500k', '> 500k']\n",
    "grouped_gdf['einwohner_kategorie'] = pd.cut(grouped_gdf['einwohner'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "grouped_gdf.plot(ax=ax,column='einwohner_kategorie', legend=True,cmap='RdYlGn_r')\n",
    "# Plot cities. \n",
    "for c in top_cities.keys():\n",
    "    # Plot city name.\n",
    "    ax.text(\n",
    "        x=top_cities[c][0], \n",
    "        # Add small shift to avoid overlap with point.\n",
    "        y=top_cities[c][1] + 0.08, \n",
    "        s=c, \n",
    "        fontsize=12,\n",
    "        ha='center', \n",
    "    )\n",
    "    # Plot city location centroid.\n",
    "    ax.plot(\n",
    "        top_cities[c][0], \n",
    "        top_cities[c][1], \n",
    "        marker='o',\n",
    "        c='black', \n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "ax.set(\n",
    "    title=\"Germany: Number of Inhabitants per 'Kreis' Code\", \n",
    "    aspect=1.4, \n",
    "    facecolor='lightblue',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = merged_df.groupby('plz_name').agg({\n",
    "    'geometry': lambda x: MultiPolygon([geom if isinstance(geom, Polygon) else geom.geoms for geom in x]),\n",
    "    'einwohner': 'sum'\n",
    "}).reset_index()\n",
    "grouped_gdf = gpd.GeoDataFrame(grouped_df, geometry='geometry')\n",
    "bins = [0, 20000, 100000, 500000, float('inf')]\n",
    "labels = ['0-20k', '20k-100k', '100k-500k', '> 500k']\n",
    "grouped_gdf['einwohner_kategorie'] = pd.cut(grouped_gdf['einwohner'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "grouped_gdf.plot(ax=ax,column='einwohner_kategorie', legend=True,cmap='RdYlGn_r')\n",
    "# Plot cities. \n",
    "for c in top_cities.keys():\n",
    "    # Plot city name.\n",
    "    ax.text(\n",
    "        x=top_cities[c][0], \n",
    "        # Add small shift to avoid overlap with point.\n",
    "        y=top_cities[c][1] + 0.08, \n",
    "        s=c, \n",
    "        fontsize=12,\n",
    "        ha='center', \n",
    "    )\n",
    "    # Plot city location centroid.\n",
    "    ax.plot(\n",
    "        top_cities[c][0], \n",
    "        top_cities[c][1], \n",
    "        marker='o',\n",
    "        c='black', \n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "ax.set(\n",
    "    title=\"Germany: Number of Inhabitants per Postal Code Name\", \n",
    "    aspect=1.4, \n",
    "    facecolor='lightblue',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_LKS01_2019_2022(fpath:str):\n",
    "    df = pd.read_excel(fpath,skiprows=3,thousands='.',decimal=',')\n",
    "    df = df.rename(columns={\n",
    "        'erfasste F채lle':'Anzahl erfasste F채lle', # 2019\n",
    "        'erfasste F채lle davon:\\nVersuche':'erfasste F채lle: Anzahl Versuche',\n",
    "        'von Spalte 3\\nVersuche':'erfasste F채lle: Anzahl Versuche', # 2019\n",
    "        'Unnamed: 6':'erfasste F채lle: Versuche in %',\n",
    "        'Tatortverteilung':'Tatortverteilung: bis unter 20.000 Einwohner',\n",
    "        'Unnamed: 8':'Tatortverteilung: 20.000 bis unter 100.000',\n",
    "        'Unnamed: 9':'Tatortverteilung: 100.000 bis unter 500.000',\n",
    "        'Unnamed: 10': 'Tatortverteilung: 500.000 und mehr',\n",
    "        'Unnamed: 11':'Tatortverteilung: unbekannt',\n",
    "        'mit Schusswaffe':'mit Schusswaffe: gedroht',\n",
    "        'Unnamed: 13':'mit Schusswaffe: geschossen',\n",
    "        'Aufkl채rung':'Aufkl채rung: Anzahl F채lle',\n",
    "        'Unnamed: 15':'Aufkl채rung: in % (AQ)',\n",
    "        'Tatverd채chtige':'Tatverd채chtige: insgesamt',\n",
    "        'Unnamed: 17':'Tatverd채chtige: m채nnlich',\n",
    "        'von Spalte 16':'Tatverd채chtige: m채nnlich',\n",
    "        'Unnamed: 18':'Tatverd채chtige: weiblich',\n",
    "        'Nichtdeutsche Tatverd채chtige':'Nichtdeutsche Tatverd채chtige: Anzahl',\n",
    "        'Unnamed: 19':'Nichtdeutsche Tatverd채chtige: Anzahl', # 2019\n",
    "        'Unnamed: 20':'Nichtdeutsche Tatverd채chtige: Anteil an TV insg. in %'\n",
    "    })\n",
    "    return df.drop(range(4)).reset_index(drop=True)\n",
    "\n",
    "def load_LKS01_2015_2018(fpath):\n",
    "    # confirmed for 2018,2017,2016,2015\n",
    "    df = pd.read_excel(fpath,skiprows=4,thousands='.',decimal=',')\n",
    "    df = df.drop(['BL-Schl.','Sort'], axis=1, errors='ignore')\n",
    "    df = df.rename(columns={\n",
    "        'erfasste F채lle':'Anzahl erfasste F채lle',\n",
    "        'von Spalte 4 Versuche':'erfasste F채lle: Anzahl Versuche',\n",
    "        'Unnamed: 6':'erfasste F채lle: Versuche in %',\n",
    "        'Unnamed: 7':'erfasste F채lle: Versuche in %', # 2018\n",
    "        'Aufkl채rung':'Aufkl채rung: Anzahl F채lle',\n",
    "        'Unnamed: 8':'Aufkl채rung: in % (AQ)', # really the same?\n",
    "        'Unnamed: 9':'Aufkl채rung: in % (AQ)', # really the same?\n",
    "        'Tatver-d채chtige insg.':'Tatverd채chtige: insgesamt',\n",
    "        'Nichtdeutsche Tat-verd채chtige':'Nichtdeutsche Tatverd채chtige: Anzahl',\n",
    "        'Unnamed: 11':'Nichtdeutsche Tatverd채chtige: Anteil an TV insg. in %',\n",
    "        'Unnamed: 12':'Nichtdeutsche Tatverd채chtige: Anteil an TV insg. in %' # 2018\n",
    "    })\n",
    "    return df.drop(range(2)).reset_index(drop=True)\n",
    "\n",
    "def load_LKS01_2014(fpath:str='Datasets/PKS/2014/tb01_FaelleGrundtabelleLaender_excel.xlsx'):\n",
    "    df = pd.read_excel(fpath,skiprows=7,thousands='.',decimal=',')\n",
    "    df = df.rename(columns={\n",
    "        'Strft. Schl.':'Schl체ssel',\n",
    "        'erfasste F채lle 2014':'Anzahl erfasste F채lle',\n",
    "        'Versuche absolut':'erfasste F채lle: Anzahl Versuche',\n",
    "        'Versuche in %':'erfasste F채lle: Versuche in %',\n",
    "        'aufgekl채rte F채lle':'Aufkl채rung: Anzahl F채lle',\n",
    "        'AQ \\nin %':'Aufkl채rung: in % (AQ)',\n",
    "        'TV insges.':'Tatverd채chtige: insgesamt',\n",
    "        'NDTV insges.':'Nichtdeutsche Tatverd채chtige: Anzahl',\n",
    "        'NDTV in %':'Nichtdeutsche Tatverd채chtige: Anteil an TV insg. in %'\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def load_LKS01_2013(fpath:str='Datasets/PKS/2013/tb01_FaelleGrundtabelleLaender_excel.xls'):\n",
    "    df = pd.read_excel(fpath,skiprows=8,thousands='.',decimal=',')\n",
    "    df = df.rename(columns={\n",
    "        'Strft. Schl.':'Schl체ssel',\n",
    "        'erfasste F채lle 2013':'Anzahl erfasste F채lle',\n",
    "        'Versuche absolut':'erfasste F채lle: Anzahl Versuche',\n",
    "        'Versuche in %':'erfasste F채lle: Versuche in %',\n",
    "        'aufgekl채rte F채lle':'Aufkl채rung: Anzahl F채lle',\n",
    "        'AQ \\nin %':'Aufkl채rung: in % (AQ)',\n",
    "        'TV insges.':'Tatverd채chtige: insgesamt',\n",
    "        'NDTV insges.':'Nichtdeutsche Tatverd채chtige: Anzahl',\n",
    "        'NDTV in %':'Nichtdeutsche Tatverd채chtige: Anteil an TV insg. in %'\n",
    "    })\n",
    "    return df\n",
    "\n",
    "class LKS01_loader(Dataset):\n",
    "    def __init__(self,root_dir:str='Datasets/PKS/'):\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.root_dir))\n",
    "    \n",
    "    def __getitem__(self,year):\n",
    "        ypath = os.path.join(self.root_dir,str(year))\n",
    "        for file in os.listdir(ypath):\n",
    "            fpath = os.path.join(ypath,file)\n",
    "            # load table for all years\n",
    "            if 2013 > year or year > 2022:\n",
    "                raise IndexError(f'No data for requested year: {year}.\\nNote: There is no official data before 2013 for this table.')\n",
    "            if any(desi in file for desi in ['LA','Laender']):\n",
    "                if 2019 <= year <= 2022:\n",
    "                    return load_LKS01_2019_2022(fpath)\n",
    "                if 2015 <= year <= 2018:\n",
    "                    return load_LKS01_2015_2018(fpath)\n",
    "                if year == 2014:\n",
    "                    return load_LKS01_2014(fpath)\n",
    "                if year == 2013:\n",
    "                    return load_LKS01_2013(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce GeoData to Federal States\n",
    "\n",
    "Problems:\n",
    "- merging GeoDataFrame on federal states leaves noisy borders (solve by shrinking and expanding with buffer; only slight loss of precision)\n",
    "- federal states in this dataset are not free of overlaps and show up in plots (solve by manually checking maps and removing overlap from the state that is too large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = gpd.read_file('Datasets/PLZ/georef-germany-postleitzahl/georef-germany-postleitzahl.shp').rename(columns={'lan_name':'Bundesland'})\n",
    "bu_geo_full = geo_df.groupby('Bundesland').agg({\n",
    "    'geometry': lambda x: MultiPolygon([geom if isinstance(geom, Polygon) else geom.geoms for geom in x])\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "# reduce geo information to outline of states\n",
    "bu_geo_reduced = bu_geo_full.copy()\n",
    "bu_geo_reduced['geometry'] = bu_geo_full['geometry'].apply(lambda x: shapely.ops.unary_union(x))\n",
    "\n",
    "# re-compute shapes with slight buffering to avoid holes where borders don't line up perfectly\n",
    "bu_geo_smooth = bu_geo_reduced.copy()\n",
    "bu_geo_smooth['geometry'] = bu_geo_reduced['geometry'].apply(\n",
    "    lambda x: x.buffer(1e-5, 1, join_style=shapely.geometry.JOIN_STYLE.mitre).buffer(-1e-4, 1, join_style=shapely.geometry.JOIN_STYLE.mitre))\n",
    "\n",
    "bu_geo_full = gpd.GeoDataFrame(bu_geo_full,geometry='geometry')\n",
    "bu_geo_reduced = gpd.GeoDataFrame(bu_geo_reduced,geometry='geometry')\n",
    "bu_geo_smooth = gpd.GeoDataFrame(bu_geo_smooth,geometry='geometry')\n",
    "\n",
    "overlaps = {'BU_1':[],'BU_2':[],'geometry':[]}\n",
    "for _,bu1 in bu_geo_smooth.iterrows(): \n",
    "    for _,bu2 in bu_geo_smooth.iterrows():\n",
    "        if bu1['Bundesland'] != bu2['Bundesland']: # problem: this only filter self-intersection, but every other intersection is considered twice\n",
    "            overlaps['BU_1'].append(bu1['Bundesland'])\n",
    "            overlaps['BU_2'].append(bu2['Bundesland'])\n",
    "            overlaps['geometry'].append(bu1.geometry.intersection(bu2.geometry))\n",
    "overlaps = gpd.GeoDataFrame(overlaps,geometry='geometry')\n",
    "overlaps = overlaps[~overlaps['geometry'].is_empty].reset_index(drop=True) # drop empty intersections\n",
    "\n",
    "fig,axs = plt.subplots(1,3)\n",
    "bu_geo_full.plot(ax=axs[0],alpha=.5,edgecolor='black')\n",
    "bu_geo_reduced.plot(ax=axs[1],alpha=.5,edgecolor='black')\n",
    "bu_geo_smooth.plot(ax=axs[2],alpha=.5,edgecolor='black')\n",
    "overlaps.plot(ax=axs[2],facecolor='red',edgecolor='none')\n",
    "for ax in axs.flatten():\n",
    "    ax.set(aspect=1.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = bu_geo_smooth.copy()\n",
    "\n",
    "def remove_intersection(region1, region2):\n",
    "    '''Removes the intersecting region from region 1\n",
    "\n",
    "    Input:\n",
    "    :param: region1: The region which is too large\n",
    "    :param: region2: The region which the area actally belongs to\n",
    "    \n",
    "    Output:\n",
    "    :return: Reduced shape of region 1'''\n",
    "\n",
    "    reduced = []\n",
    "    for pol1 in region1:\n",
    "        for pol2 in region2:\n",
    "            if pol1.intersects(pol2):\n",
    "                # If they intersect, create a new polygon that is\n",
    "                # essentially pol minus the intersection\n",
    "                nonoverlap = (pol1.symmetric_difference(pol2)).difference(pol2)\n",
    "                reduced.append(list(nonoverlap.geoms) if isinstance(nonoverlap,MultiPolygon) else nonoverlap)\n",
    "            else:\n",
    "                # Otherwise, just keep the initial polygon as it is.\n",
    "                reduced.append(pol1)\n",
    "                \n",
    "    return shapely.ops.unary_union(reduced)\n",
    "\n",
    "def cleanBU_(df,bu1,bu2):\n",
    "    df.loc[df.loc[:,\"Bundesland\"] == bu1,\"geometry\"] = remove_intersection(\n",
    "        df.loc[df.loc[:,\"Bundesland\"] == bu1,\"geometry\"],\n",
    "        df.loc[df.loc[:,\"Bundesland\"] == bu2,\"geometry\"])\n",
    "\n",
    "cleanBU_(geo,\"Hessen\",\"Niedersachsen\")\n",
    "cleanBU_(geo,\"Hessen\",\"Rheinland-Pfalz\")\n",
    "cleanBU_(geo,\"Hessen\",\"Nordrhein-Westfalen\")\n",
    "cleanBU_(geo,\"Bayern\",\"Baden-W체rttemberg\")\n",
    "cleanBU_(geo,\"Baden-W체rttemberg\",\"Hessen\")\n",
    "cleanBU_(geo,\"Th체ringen\",\"Sachsen\")\n",
    "cleanBU_(geo,\"Schleswig-Holstein\",\"Hamburg\")\n",
    "cleanBU_(geo,\"Mecklenburg-Vorpommern\",\"Niedersachsen\")\n",
    "cleanBU_(geo,\"Mecklenburg-Vorpommern\",\"Brandenburg\")\n",
    "cleanBU_(geo,\"Sachsen-Anhalt\",\"Brandenburg\")\n",
    "\n",
    "geo.plot(alpha=0.5,aspect=1.3,edgecolor='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = LKS01_loader()[2022]\n",
    "cases = df.loc[df['Schl체ssel'] == '------']\n",
    "merged_df = pd.merge(cases,geo,on='Bundesland')\n",
    "merged_df = gpd.GeoDataFrame(merged_df, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = 'RdYlGn_r'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "merged_df.plot(ax=ax,column='Anzahl erfasste F채lle', legend=True,cmap=cmap,legend_kwds={'label':'Absolute number of crimes'})\n",
    "plot_cities(ax)\n",
    "ax.set(\n",
    "    title=\"Germany 2022: Crimes per federal state\", \n",
    "    aspect=1.4, \n",
    "    facecolor='lightblue',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cybercrime per federal state over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might take ~20 seconds\n",
    "data = LKS01_loader()\n",
    "merged_data = []\n",
    "# no \"%-Anteil an allen F채llen\" column available before 2019; compute it manually:\n",
    "print('Loading 2013 - 2022 ...')\n",
    "for year in range(2013,2019):\n",
    "    print(f'Year: {year}', end=\"\\r\", flush=True)\n",
    "    df_year = data[year]\n",
    "    df_year_all = df_year[df_year['Schl체ssel'] == '------']['Anzahl erfasste F채lle'].to_numpy()\n",
    "    df_year = df_year.loc[df_year['Schl체ssel'] == '897000']\n",
    "    df_year['%-Anteil an allen F채llen'] = df_year['Anzahl erfasste F채lle'].to_numpy() / df_year_all * 100\n",
    "    merged_year = pd.merge(df_year,geo,on='Bundesland')\n",
    "    merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))\n",
    "for year in range(2019,2023):\n",
    "    print(year)\n",
    "    df_year = data[year]\n",
    "    df_year = df_year.loc[df_year['Schl체ssel'] == '897000']\n",
    "    merged_year = pd.merge(df_year,geo,on='Bundesland')\n",
    "    merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = min([min(x.loc[:,'%-Anteil an allen F채llen']) for x in merged_data])\n",
    "vmax = max([max(x.loc[:,'%-Anteil an allen F채llen']) for x in merged_data])\n",
    "\n",
    "fig, axs = plt.subplots(3,4,layout='constrained',figsize=(8,7))\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "    if i < len(merged_data):\n",
    "        merged_data[i].plot(ax=ax,column='%-Anteil an allen F채llen', legend=False, cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "        ax.set(aspect=1.4,title=i+2013)\n",
    "    ax.set_axis_off()\n",
    "    if i == len(merged_data):\n",
    "        plot_cbar(ax,vmin,vmax,cmap,'% of all crime')\n",
    "fig.suptitle(\"Germany: Cybercrime per federal state (relative)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh? Shouldn't 2020 and 2021 be overall higher than other years? (see temporal analysis)\n",
    "\n",
    "Problem: For some reason the fraction of all crime in 2020 and 2021 is not computed wrt. the number of crimes in each federal state, but in all of Germany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fraction(df_year):\n",
    "    df_year_all = df_year[df_year['Schl체ssel'] == '------']['Anzahl erfasste F채lle'].to_numpy()\n",
    "    df_year = df_year.loc[df_year['Schl체ssel'] == '897000'].copy()\n",
    "    if '%-Anteil an allen F채llen' in df_year.columns:\n",
    "        df_year.loc[:,'%-Anteil an allen F채llen'] = df_year['Anzahl erfasste F채lle'].to_numpy() / df_year_all * 100\n",
    "    else:\n",
    "       df_year['%-Anteil an allen F채llen'] = df_year['Anzahl erfasste F채lle'].to_numpy() / df_year_all * 100\n",
    "    return pd.merge(df_year,geo,on='Bundesland')\n",
    "\n",
    "data = LKS01_loader()\n",
    "merged_data = []\n",
    "# no \"%-Anteil an allen F채llen\" column available before 2019; compute it manually and fix 2020,2021:\n",
    "print('Loading 2013 - 2022 ...')\n",
    "for year in range(2013,2023):\n",
    "    print(f'Year: {year}', end=\"\\r\", flush=True)\n",
    "    df_year = data[year]\n",
    "    if year in [2019,2022]:\n",
    "        df_year = df_year.loc[df_year['Schl체ssel'] == '897000']\n",
    "        merged_year = pd.merge(df_year,geo,on='Bundesland')\n",
    "        merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))\n",
    "    else:\n",
    "        merged_year = add_fraction(df_year)\n",
    "        merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = min([min(x.loc[:,'%-Anteil an allen F채llen']) for x in merged_data])\n",
    "vmax = max([max(x.loc[:,'%-Anteil an allen F채llen']) for x in merged_data])\n",
    "\n",
    "fig, axs = plt.subplots(3,4,layout='constrained',figsize=(8,7))\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "    if i < len(merged_data):\n",
    "        im = merged_data[i].plot(ax=ax,column='%-Anteil an allen F채llen', legend=False, cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "        ax.set(aspect=1.4,title=i+2013)\n",
    "    ax.set_axis_off()\n",
    "    if i == len(merged_data):\n",
    "        plot_cbar(ax,vmin,vmax,cmap,'% of all crime')\n",
    "fig.suptitle(\"Germany: Cybercrime per federal state (relative)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fraud\n",
    "Summenschl체ssel:\n",
    "\n",
    "510000: Betrug 짠짠 263, 263a, 264, 264a, 265, 265a-e StGB\n",
    "\n",
    "897100: Computerbetrug 짠 263a StGB\n",
    "\n",
    "\"Analog\" = 51000 - 897100\n",
    "\n",
    "\"Digital\" = 897100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = LKS01_loader()\n",
    "merged_data = []\n",
    "# sumkey 897100 did not exist before 2016 (maybe also an explanation why we see sudden increase in cybercrime for that year)\n",
    "print('Loading 2016 - 2022 ...')\n",
    "for year in range(2016,2023):\n",
    "    print(f'Year: {year}', end=\"\\r\", flush=True)\n",
    "    df_year = data[year]\n",
    "    df_year_fraud = df_year.loc[df_year['Schl체ssel'] == '510000']\n",
    "    df_year_cfraud = df_year.loc[df_year['Schl체ssel'] == '897100']\n",
    "    df_year_ratio = pd.DataFrame({'Bundesland':df_year_fraud['Bundesland'],\n",
    "                                  'Anteil':np.array(df_year_cfraud['Anzahl erfasste F채lle']) /\n",
    "                                  (np.array(df_year_fraud['Anzahl erfasste F채lle']) - np.array(df_year_cfraud['Anzahl erfasste F채lle'])) * 100})\n",
    "    merged_year = pd.merge(df_year_ratio,geo,on='Bundesland')\n",
    "    merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = min([min(x.loc[:,'Anteil']) for x in merged_data])\n",
    "vmax = max([max(x.loc[:,'Anteil']) for x in merged_data])\n",
    "\n",
    "fig, axs = plt.subplots(3,3,layout='constrained',figsize=(6,7))\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "    if i < len(merged_data):\n",
    "        merged_data[i].plot(ax=ax,column='Anteil', legend=False, cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "        ax.set(aspect=1.4,title=i+2016)\n",
    "    ax.set_axis_off()\n",
    "    if i == len(merged_data):\n",
    "        plot_cbar(ax,vmin,vmax,cmap,'% of all fraud')\n",
    "fig.suptitle(\"Germany: Computer fraud\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhabitants_bu = {'Baden-W체rttemberg':11124642,\n",
    "                'Bayern':13176989,\n",
    "                'Berlin':3677472,\n",
    "                'Brandenburg':2537868,\n",
    "                'Bremen':676463,\n",
    "                'Hamburg':1853935,\n",
    "                'Hessen':6295017,\n",
    "                'Mecklenburg-Vorpommern':1611160,\n",
    "                'Niedersachsen':8027031,\n",
    "                'Nordrhein-Westfalen':17924591,\n",
    "                'Rheinland-Pfalz':4106485,\n",
    "                'Saarland':982348,\n",
    "                'Sachsen':4043002,\n",
    "                'Sachsen-Anhalt':2169253,\n",
    "                'Schleswig-Holstein':2922005,\n",
    "                'Th체ringen':2108863,\n",
    "                'Bundesrepublik Deutschland':84358845}\n",
    "inhabs = np.array([11124642,13176989,3677472,2537868,676463,1853935,6295017,1611160,8027031,17924591,4106485,982348,4043002,2169253,2922005,2108863,84358845])\n",
    "\n",
    "\n",
    "data = LKS01_loader()\n",
    "merged_data = []\n",
    "print('Loading 2013 - 2022 ...')\n",
    "for year in range(2013,2019):\n",
    "    print(f'Year: {year}', end=\"\\r\", flush=True)\n",
    "    df_year = data[year]\n",
    "    cases = df_year.loc[df_year['Schl체ssel'] == '------']\n",
    "    merged_year = pd.merge(cases,geo,on='Bundesland')\n",
    "    merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))\n",
    "for year in range(2019,2023):\n",
    "    print(f'Year: {year}', end=\"\\r\", flush=True)\n",
    "    df_year = data[year]\n",
    "    cases = df_year.loc[df_year['Schl체ssel'] == '------'].copy() # explicitly copying here takes way longer, but gets rid of the warnings...\n",
    "    cases['HZ nach Zensus'] = cases['Anzahl erfasste F채lle'].to_numpy() / inhabs * 1e5\n",
    "    merged_year = pd.merge(cases,geo,on='Bundesland')\n",
    "    merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = min([min(x.loc[:,'HZ nach Zensus']) for x in merged_data])\n",
    "vmax = max([max(x.loc[:,'HZ nach Zensus']) for x in merged_data])\n",
    "\n",
    "fig, axs = plt.subplots(3,4,layout='constrained',figsize=(8,7))\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "    if i < len(merged_data):\n",
    "        merged_data[i].plot(ax=ax,column='HZ nach Zensus', legend=False, cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "        ax.set(aspect=1.4,title=i+2013)\n",
    "    ax.set_axis_off()\n",
    "    if i == len(merged_data):\n",
    "        plot_cbar(ax,vmin,vmax,cmap)\n",
    "fig.suptitle(\"Germany: Crimes per Capita and Federal State\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
