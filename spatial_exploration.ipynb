{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from shapely.geometry import MultiPolygon,Polygon\n",
    "import shapely\n",
    "from src.PlotFuncitons import *\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' # does not affect other users\n",
    "# or consider setting your dpi in rcParams to a reasonably high value (also important for exporting if not explicitly given)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cooler Blog zu Mapping\n",
    "Folgendes ist aus dem Artikel:\n",
    "https://juanitorduz.github.io/germany_plots/\n",
    "\n",
    "Sein Skript geht noch weiter, allerdings ist das für uns nicht relevant. Falls in den späteren Zellen was nicht funktioniert wie erwartet: Alle Zellen ab hier nochmal laufen lassen. Viele Operationen sind mehr oder weniger offensichtlich inplace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure you read postal codes as strings, otherwise \n",
    "# the postal code 01110 will be parsed as the number 1110. \n",
    "plz_shape_df = gpd.read_file('Datasets/PLZ/plz-5stellig/plz-5stellig.shp', dtype={'plz': str}) # ,encoding='Windows-1252')\n",
    "plz_shape_df.drop(['einwohner','qkm'],axis=1,inplace=True)\n",
    "plz_shape_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [16, 11]\n",
    "\n",
    "# Get lat and lng of Germany's main cities. \n",
    "top_cities = {\n",
    "    'Berlin': (13.404954, 52.520008), \n",
    "    'Cologne': (6.953101, 50.935173),\n",
    "    'Düsseldorf': (6.782048, 51.227144),\n",
    "    'Frankfurt am Main': (8.682127, 50.110924),\n",
    "    'Hamburg': (9.993682, 53.551086),\n",
    "    'Leipzig': (12.387772, 51.343479),\n",
    "    'Munich': (11.576124, 48.137154),\n",
    "    'Dortmund': (7.468554, 51.513400),\n",
    "    'Stuttgart': (9.181332, 48.777128),\n",
    "    'Nuremberg': (11.077438, 49.449820),\n",
    "    'Hannover': (9.73322, 52.37052)\n",
    "}\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plz_shape_df.plot(ax=ax, color='orange', alpha=0.8)\n",
    "\n",
    "# Plot cities. \n",
    "for c in top_cities.keys():\n",
    "    # Plot city name.\n",
    "    ax.text(\n",
    "        x=top_cities[c][0], \n",
    "        # Add small shift to avoid overlap with point.\n",
    "        y=top_cities[c][1] + 0.08, \n",
    "        s=c, \n",
    "        fontsize=12,\n",
    "        ha='center', \n",
    "    )\n",
    "    # Plot city location centroid.\n",
    "    ax.plot(\n",
    "        top_cities[c][0], \n",
    "        top_cities[c][1], \n",
    "        marker='o',\n",
    "        c='black', \n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "ax.set(\n",
    "    title='Germany', \n",
    "    aspect=1.4, \n",
    "    facecolor='lightblue'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feature.\n",
    "plz_shape_df = plz_shape_df.assign(first_dig_plz = lambda x: x['plz'].str.slice(start=0, stop=1))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "plz_shape_df.plot(\n",
    "    ax=ax, \n",
    "    column='first_dig_plz', \n",
    "    categorical=True, \n",
    "    legend=True, \n",
    "    legend_kwds={'title':'First Digit', 'loc':'lower right'},\n",
    "    cmap='tab20',\n",
    "    alpha=0.9\n",
    ")\n",
    "\n",
    "for c in top_cities.keys():\n",
    "\n",
    "    ax.text(\n",
    "        x=top_cities[c][0], \n",
    "        y=top_cities[c][1] + 0.08, \n",
    "        s=c, \n",
    "        fontsize=12,\n",
    "        ha='center', \n",
    "    )\n",
    "\n",
    "    ax.plot(\n",
    "        top_cities[c][0], \n",
    "        top_cities[c][1], \n",
    "        marker='o',\n",
    "        c='black', \n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "ax.set(\n",
    "    title='Germany First-Digit-Postal Codes Areas', \n",
    "    aspect=1.4,\n",
    "    facecolor='white'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plz_region_df = pd.read_csv(\n",
    "    'Datasets/PLZ/zuordnung_plz_ort.csv', \n",
    "    sep=',', \n",
    "    dtype={'plz': str}\n",
    ")\n",
    "\n",
    "plz_region_df.drop(['osm_id','ags','landkreis'], axis=1, inplace=True)\n",
    "\n",
    "plz_region_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data.\n",
    "germany_df = pd.merge(\n",
    "    left=plz_shape_df, \n",
    "    right=plz_region_df, \n",
    "    on='plz',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "germany_df.drop(['note'], axis=1, inplace=True)\n",
    "\n",
    "germany_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "germany_df.plot(\n",
    "    ax=ax, \n",
    "    column='bundesland', \n",
    "    categorical=True, \n",
    "    legend=True, \n",
    "    legend_kwds={'title':'Bundesland', 'bbox_to_anchor': (1.35, 0.8)},\n",
    "    cmap='tab20',\n",
    "    alpha=0.9\n",
    ")\n",
    "\n",
    "for c in top_cities.keys():\n",
    "\n",
    "    ax.text(\n",
    "        x=top_cities[c][0], \n",
    "        y=top_cities[c][1] + 0.08, \n",
    "        s=c, \n",
    "        fontsize=12,\n",
    "        ha='center', \n",
    "    )\n",
    "\n",
    "    ax.plot(\n",
    "        top_cities[c][0], \n",
    "        top_cities[c][1], \n",
    "        marker='o',\n",
    "        c='black', \n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "ax.set(\n",
    "    title='Germany - Bundesländer', \n",
    "    aspect=1.4, \n",
    "    facecolor='white'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plz_einwohner_df = pd.read_csv(\n",
    "    'Datasets/PLZ/plz_einwohner.csv', \n",
    "    sep=',', \n",
    "    dtype={'plz': str, 'einwohner': int}\n",
    ")\n",
    "plz_einwohner_df.drop(['note','qkm','lat','lon'],axis=1,inplace=True)\n",
    "plz_einwohner_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data.\n",
    "germany_df = pd.merge(\n",
    "    left=germany_df, \n",
    "    right=plz_einwohner_df, \n",
    "    on='plz',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "germany_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "germany_df.plot(\n",
    "    ax=ax, \n",
    "    column='einwohner', \n",
    "    categorical=False, \n",
    "    legend=True, \n",
    "    cmap='RdYlGn_r',\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "for c in top_cities.keys():\n",
    "\n",
    "    ax.text(\n",
    "        x=top_cities[c][0], \n",
    "        y=top_cities[c][1] + 0.08, \n",
    "        s=c, \n",
    "        fontsize=12,\n",
    "        ha='center', \n",
    "    )\n",
    "\n",
    "    ax.plot(\n",
    "        top_cities[c][0], \n",
    "        top_cities[c][1], \n",
    "        marker='o',\n",
    "        c='black', \n",
    "        alpha=0.5\n",
    "    )\n",
    "    \n",
    "ax.set(\n",
    "    title='Germany: Number of Inhabitants per Postal Code', \n",
    "    aspect=1.4, \n",
    "    facecolor='lightblue'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0, 20000, 100000, 500000, float('inf')]\n",
    "labels = ['0-20k', '20k-100k', '100k-500k', '> 500k']\n",
    "germany_df['einwohner_kategorie'] = pd.cut(germany_df['einwohner'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "germany_df.plot(\n",
    "    ax=ax, \n",
    "    column='einwohner_kategorie', \n",
    "    legend=True, \n",
    "    cmap='RdYlGn_r',\n",
    "    alpha=0.8\n",
    ")\n",
    "\n",
    "for c in top_cities.keys():\n",
    "\n",
    "    ax.text(\n",
    "        x=top_cities[c][0], \n",
    "        y=top_cities[c][1] + 0.08, \n",
    "        s=c, \n",
    "        fontsize=12,\n",
    "        ha='center', \n",
    "    )\n",
    "\n",
    "    ax.plot(\n",
    "        top_cities[c][0], \n",
    "        top_cities[c][1], \n",
    "        marker='o',\n",
    "        c='black', \n",
    "        alpha=0.5\n",
    "    )\n",
    "    \n",
    "ax.set(\n",
    "    title='Germany: Number of Inhabitants per Postal Code', \n",
    "    aspect=1.4, \n",
    "    facecolor='lightblue'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ab hier kommt wieder meine Code Ursuppe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = gpd.read_file('Datasets/PLZ/plz-5stellig/plz-5stellig.shp', dtype={'plz': str})\n",
    "plz_map = pd.read_csv('Datasets/PLZ/georef-germany-postleitzahl.csv',sep=';',dtype={'Postleitzahl / Post code':str})\n",
    "plz_map = plz_map.rename(columns={'Postleitzahl / Post code':'plz'})\n",
    "merged_df = pd.merge(geo_df, plz_map, on='plz',how='left')\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = merged_df.groupby('PLZ Name (short)').agg({\n",
    "    'geometry': lambda x: MultiPolygon([geom if isinstance(geom, Polygon) else geom.geoms for geom in x]),\n",
    "    'einwohner': 'sum'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "grouped_gdf = gpd.GeoDataFrame(grouped_df, geometry='geometry')\n",
    "\n",
    "bins = [0, 20000, 100000, 500000, float('inf')]\n",
    "labels = ['0-20k', '20k-100k', '100k-500k', '> 500k']\n",
    "\n",
    "grouped_gdf['einwohner_kategorie'] = pd.cut(grouped_gdf['einwohner'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "grouped_gdf.plot(ax=ax,column='einwohner_kategorie', legend=True,cmap='RdYlGn_r')\n",
    "ax.set(\n",
    "    title='Germany: Number of Inhabitants per Postal Code', \n",
    "    aspect=1.3, \n",
    "    facecolor='lightblue'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = gpd.read_file('Datasets/PLZ/georef-germany-postleitzahl/georef-germany-postleitzahl.shp')\n",
    "geo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "geo_df.plot(\n",
    "    ax=ax, \n",
    "    column='lan_code', \n",
    "    categorical=True, \n",
    "    legend=True, \n",
    "    legend_kwds={'title':'First Digit', 'loc':'lower right'},\n",
    "    cmap='tab20',\n",
    "    alpha=.7\n",
    ")\n",
    "# Plot cities. \n",
    "for c in top_cities.keys():\n",
    "    # Plot city name.\n",
    "    ax.text(\n",
    "        x=top_cities[c][0], \n",
    "        # Add small shift to avoid overlap with point.\n",
    "        y=top_cities[c][1] + 0.08, \n",
    "        s=c, \n",
    "        fontsize=12,\n",
    "        ha='center', \n",
    "    )\n",
    "    # Plot city location centroid.\n",
    "    ax.plot(\n",
    "        top_cities[c][0], \n",
    "        top_cities[c][1], \n",
    "        marker='o',\n",
    "        c='black', \n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "ax.set(\n",
    "    title='Germany', \n",
    "    aspect=1.4, \n",
    "    facecolor='lightblue',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhabitans_df = pd.read_csv('Datasets/PLZ/plz_einwohner.csv',dtype={'plz':str}).rename(columns={'plz':'plz_code'})\n",
    "merged_df = pd.merge(geo_df,inhabitans_df,on='plz_code',how='left')\n",
    "merged_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = merged_df.groupby('krs_code').agg({\n",
    "    'geometry': lambda x: MultiPolygon([geom if isinstance(geom, Polygon) else geom.geoms for geom in x]),\n",
    "    'einwohner': 'sum'\n",
    "}).reset_index()\n",
    "grouped_gdf = gpd.GeoDataFrame(grouped_df, geometry='geometry')\n",
    "bins = [0, 20000, 100000, 500000, float('inf')]\n",
    "labels = ['0-20k', '20k-100k', '100k-500k', '> 500k']\n",
    "grouped_gdf['einwohner_kategorie'] = pd.cut(grouped_gdf['einwohner'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "grouped_gdf.plot(ax=ax,column='einwohner_kategorie', legend=True,cmap='RdYlGn_r')\n",
    "# Plot cities. \n",
    "for c in top_cities.keys():\n",
    "    # Plot city name.\n",
    "    ax.text(\n",
    "        x=top_cities[c][0], \n",
    "        # Add small shift to avoid overlap with point.\n",
    "        y=top_cities[c][1] + 0.08, \n",
    "        s=c, \n",
    "        fontsize=12,\n",
    "        ha='center', \n",
    "    )\n",
    "    # Plot city location centroid.\n",
    "    ax.plot(\n",
    "        top_cities[c][0], \n",
    "        top_cities[c][1], \n",
    "        marker='o',\n",
    "        c='black', \n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "ax.set(\n",
    "    title=\"Germany: Number of Inhabitants per 'Kreis' Code\", \n",
    "    aspect=1.4, \n",
    "    facecolor='lightblue',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = merged_df.groupby('plz_name').agg({\n",
    "    'geometry': lambda x: MultiPolygon([geom if isinstance(geom, Polygon) else geom.geoms for geom in x]),\n",
    "    'einwohner': 'sum'\n",
    "}).reset_index()\n",
    "grouped_gdf = gpd.GeoDataFrame(grouped_df, geometry='geometry')\n",
    "bins = [0, 20000, 100000, 500000, float('inf')]\n",
    "labels = ['0-20k', '20k-100k', '100k-500k', '> 500k']\n",
    "grouped_gdf['einwohner_kategorie'] = pd.cut(grouped_gdf['einwohner'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "grouped_gdf.plot(ax=ax,column='einwohner_kategorie', legend=True,cmap='RdYlGn_r')\n",
    "# Plot cities. \n",
    "for c in top_cities.keys():\n",
    "    # Plot city name.\n",
    "    ax.text(\n",
    "        x=top_cities[c][0], \n",
    "        # Add small shift to avoid overlap with point.\n",
    "        y=top_cities[c][1] + 0.08, \n",
    "        s=c, \n",
    "        fontsize=12,\n",
    "        ha='center', \n",
    "    )\n",
    "    # Plot city location centroid.\n",
    "    ax.plot(\n",
    "        top_cities[c][0], \n",
    "        top_cities[c][1], \n",
    "        marker='o',\n",
    "        c='black', \n",
    "        alpha=0.5\n",
    "    )\n",
    "\n",
    "ax.set(\n",
    "    title=\"Germany: Number of Inhabitants per Postal Code Name\", \n",
    "    aspect=1.4, \n",
    "    facecolor='lightblue',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_LKS01_2019_2022(fpath:str):\n",
    "    df = pd.read_excel(fpath,skiprows=3,thousands='.',decimal=',')\n",
    "    df = df.rename(columns={\n",
    "        'erfasste Fälle':'Anzahl erfasste Fälle', # 2019\n",
    "        'erfasste Fälle davon:\\nVersuche':'erfasste Fälle: Anzahl Versuche',\n",
    "        'von Spalte 3\\nVersuche':'erfasste Fälle: Anzahl Versuche', # 2019\n",
    "        'Unnamed: 6':'erfasste Fälle: Versuche in %',\n",
    "        'Tatortverteilung':'Tatortverteilung: bis unter 20.000 Einwohner',\n",
    "        'Unnamed: 8':'Tatortverteilung: 20.000 bis unter 100.000',\n",
    "        'Unnamed: 9':'Tatortverteilung: 100.000 bis unter 500.000',\n",
    "        'Unnamed: 10': 'Tatortverteilung: 500.000 und mehr',\n",
    "        'Unnamed: 11':'Tatortverteilung: unbekannt',\n",
    "        'mit Schusswaffe':'mit Schusswaffe: gedroht',\n",
    "        'Unnamed: 13':'mit Schusswaffe: geschossen',\n",
    "        'Aufklärung':'Aufklärung: Anzahl Fälle',\n",
    "        'Unnamed: 15':'Aufklärung: in % (AQ)',\n",
    "        'Tatverdächtige':'Tatverdächtige: insgesamt',\n",
    "        'Unnamed: 17':'Tatverdächtige: männlich',\n",
    "        'von Spalte 16':'Tatverdächtige: männlich',\n",
    "        'Unnamed: 18':'Tatverdächtige: weiblich',\n",
    "        'Nichtdeutsche Tatverdächtige':'Nichtdeutsche Tatverdächtige: Anzahl',\n",
    "        'Unnamed: 19':'Nichtdeutsche Tatverdächtige: Anzahl', # 2019\n",
    "        'Unnamed: 20':'Nichtdeutsche Tatverdächtige: Anteil an TV insg. in %'\n",
    "    })\n",
    "    return df.drop(range(4)).reset_index(drop=True)\n",
    "\n",
    "def load_LKS01_2015_2018(fpath):\n",
    "    # confirmed for 2018,2017,2016,2015\n",
    "    df = pd.read_excel(fpath,skiprows=4,thousands='.',decimal=',')\n",
    "    df = df.drop(['BL-Schl.','Sort'], axis=1, errors='ignore')\n",
    "    df = df.rename(columns={\n",
    "        'erfasste Fälle':'Anzahl erfasste Fälle',\n",
    "        'von Spalte 4 Versuche':'erfasste Fälle: Anzahl Versuche',\n",
    "        'Unnamed: 6':'erfasste Fälle: Versuche in %',\n",
    "        'Unnamed: 7':'erfasste Fälle: Versuche in %', # 2018\n",
    "        'Aufklärung':'Aufklärung: Anzahl Fälle',\n",
    "        'Unnamed: 8':'Aufklärung: in % (AQ)', # really the same?\n",
    "        'Unnamed: 9':'Aufklärung: in % (AQ)', # really the same?\n",
    "        'Tatver-dächtige insg.':'Tatverdächtige: insgesamt',\n",
    "        'Nichtdeutsche Tat-verdächtige':'Nichtdeutsche Tatverdächtige: Anzahl',\n",
    "        'Unnamed: 11':'Nichtdeutsche Tatverdächtige: Anteil an TV insg. in %',\n",
    "        'Unnamed: 12':'Nichtdeutsche Tatverdächtige: Anteil an TV insg. in %' # 2018\n",
    "    })\n",
    "    return df.drop(range(2)).reset_index(drop=True)\n",
    "\n",
    "def load_LKS01_2014(fpath:str='Datasets/PKS/2014/tb01_FaelleGrundtabelleLaender_excel.xlsx'):\n",
    "    df = pd.read_excel(fpath,skiprows=7,thousands='.',decimal=',')\n",
    "    df = df.rename(columns={\n",
    "        'Strft. Schl.':'Schlüssel',\n",
    "        'erfasste Fälle 2014':'Anzahl erfasste Fälle',\n",
    "        'Versuche absolut':'erfasste Fälle: Anzahl Versuche',\n",
    "        'Versuche in %':'erfasste Fälle: Versuche in %',\n",
    "        'aufgeklärte Fälle':'Aufklärung: Anzahl Fälle',\n",
    "        'AQ \\nin %':'Aufklärung: in % (AQ)',\n",
    "        'TV insges.':'Tatverdächtige: insgesamt',\n",
    "        'NDTV insges.':'Nichtdeutsche Tatverdächtige: Anzahl',\n",
    "        'NDTV in %':'Nichtdeutsche Tatverdächtige: Anteil an TV insg. in %'\n",
    "    })\n",
    "    return df\n",
    "\n",
    "def load_LKS01_2013(fpath:str='Datasets/PKS/2013/tb01_FaelleGrundtabelleLaender_excel.xls'):\n",
    "    df = pd.read_excel(fpath,skiprows=8,thousands='.',decimal=',')\n",
    "    df = df.rename(columns={\n",
    "        'Strft. Schl.':'Schlüssel',\n",
    "        'erfasste Fälle 2013':'Anzahl erfasste Fälle',\n",
    "        'Versuche absolut':'erfasste Fälle: Anzahl Versuche',\n",
    "        'Versuche in %':'erfasste Fälle: Versuche in %',\n",
    "        'aufgeklärte Fälle':'Aufklärung: Anzahl Fälle',\n",
    "        'AQ \\nin %':'Aufklärung: in % (AQ)',\n",
    "        'TV insges.':'Tatverdächtige: insgesamt',\n",
    "        'NDTV insges.':'Nichtdeutsche Tatverdächtige: Anzahl',\n",
    "        'NDTV in %':'Nichtdeutsche Tatverdächtige: Anteil an TV insg. in %'\n",
    "    })\n",
    "    return df\n",
    "\n",
    "class LKS01_loader(Dataset):\n",
    "    def __init__(self,root_dir:str='Datasets/PKS/'):\n",
    "        self.root_dir = root_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.root_dir))\n",
    "    \n",
    "    def __getitem__(self,year):\n",
    "        ypath = os.path.join(self.root_dir,str(year))\n",
    "        for file in os.listdir(ypath):\n",
    "            fpath = os.path.join(ypath,file)\n",
    "            # load table for all years\n",
    "            if 2013 > year or year > 2022:\n",
    "                raise IndexError(f'No data for requested year: {year}.\\nNote: There is no official data before 2013 for this table.')\n",
    "            if any(desi in file for desi in ['LA','Laender']):\n",
    "                if 2019 <= year <= 2022:\n",
    "                    return load_LKS01_2019_2022(fpath)\n",
    "                if 2015 <= year <= 2018:\n",
    "                    return load_LKS01_2015_2018(fpath)\n",
    "                if year == 2014:\n",
    "                    return load_LKS01_2014(fpath)\n",
    "                if year == 2013:\n",
    "                    return load_LKS01_2013(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce GeoData to Federal States\n",
    "\n",
    "Problems:\n",
    "- merging GeoDataFrame on federal states leaves noisy borders (solve by shrinking and expanding with buffer; only slight loss of precision)\n",
    "- federal states in this dataset are not free of overlaps and show up in plots (solve by manually checking maps and removing overlap from the state that is too large)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_df = gpd.read_file('Datasets/PLZ/georef-germany-postleitzahl/georef-germany-postleitzahl.shp').rename(columns={'lan_name':'Bundesland'})\n",
    "bu_geo_full = geo_df.groupby('Bundesland').agg({\n",
    "    'geometry': lambda x: MultiPolygon([geom if isinstance(geom, Polygon) else geom.geoms for geom in x])\n",
    "}).reset_index()\n",
    "\n",
    "\n",
    "# reduce geo information to outline of states\n",
    "bu_geo_reduced = bu_geo_full.copy()\n",
    "bu_geo_reduced['geometry'] = bu_geo_full['geometry'].apply(lambda x: shapely.ops.unary_union(x))\n",
    "\n",
    "# re-compute shapes with slight buffering to avoid holes where borders don't line up perfectly\n",
    "bu_geo_smooth = bu_geo_reduced.copy()\n",
    "bu_geo_smooth['geometry'] = bu_geo_reduced['geometry'].apply(\n",
    "    lambda x: x.buffer(1e-5, 1, join_style=shapely.geometry.JOIN_STYLE.mitre).buffer(-1e-4, 1, join_style=shapely.geometry.JOIN_STYLE.mitre))\n",
    "\n",
    "bu_geo_full = gpd.GeoDataFrame(bu_geo_full,geometry='geometry')\n",
    "bu_geo_reduced = gpd.GeoDataFrame(bu_geo_reduced,geometry='geometry')\n",
    "bu_geo_smooth = gpd.GeoDataFrame(bu_geo_smooth,geometry='geometry')\n",
    "\n",
    "overlaps = {'BU_1':[],'BU_2':[],'geometry':[]}\n",
    "for _,bu1 in bu_geo_smooth.iterrows(): \n",
    "    for _,bu2 in bu_geo_smooth.iterrows():\n",
    "        if bu1['Bundesland'] != bu2['Bundesland']: # problem: this only filter self-intersection, but every other intersection is considered twice\n",
    "            overlaps['BU_1'].append(bu1['Bundesland'])\n",
    "            overlaps['BU_2'].append(bu2['Bundesland'])\n",
    "            overlaps['geometry'].append(bu1.geometry.intersection(bu2.geometry))\n",
    "overlaps = gpd.GeoDataFrame(overlaps,geometry='geometry')\n",
    "overlaps = overlaps[~overlaps['geometry'].is_empty].reset_index(drop=True) # drop empty intersections\n",
    "\n",
    "fig,axs = plt.subplots(1,3)\n",
    "bu_geo_full.plot(ax=axs[0],alpha=.5,edgecolor='black')\n",
    "bu_geo_reduced.plot(ax=axs[1],alpha=.5,edgecolor='black')\n",
    "bu_geo_smooth.plot(ax=axs[2],alpha=.5,edgecolor='black')\n",
    "overlaps.plot(ax=axs[2],facecolor='red',edgecolor='none')\n",
    "for ax in axs.flatten():\n",
    "    ax.set(aspect=1.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo = bu_geo_smooth.copy()\n",
    "\n",
    "def remove_intersection(region1, region2):\n",
    "    '''Removes the intersecting region from region 1\n",
    "\n",
    "    Input:\n",
    "    :param: region1: The region which is too large\n",
    "    :param: region2: The region which the area actally belongs to\n",
    "    \n",
    "    Output:\n",
    "    :return: Reduced shape of region 1'''\n",
    "\n",
    "    reduced = []\n",
    "    for pol1 in region1:\n",
    "        for pol2 in region2:\n",
    "            if pol1.intersects(pol2):\n",
    "                # If they intersect, create a new polygon that is\n",
    "                # essentially pol minus the intersection\n",
    "                nonoverlap = (pol1.symmetric_difference(pol2)).difference(pol2)\n",
    "                reduced.append(list(nonoverlap.geoms) if isinstance(nonoverlap,MultiPolygon) else nonoverlap)\n",
    "            else:\n",
    "                # Otherwise, just keep the initial polygon as it is.\n",
    "                reduced.append(pol1)\n",
    "                \n",
    "    return shapely.ops.unary_union(reduced)\n",
    "\n",
    "def cleanBU_(df,bu1,bu2):\n",
    "    df.loc[df.loc[:,\"Bundesland\"] == bu1,\"geometry\"] = remove_intersection(\n",
    "        df.loc[df.loc[:,\"Bundesland\"] == bu1,\"geometry\"],\n",
    "        df.loc[df.loc[:,\"Bundesland\"] == bu2,\"geometry\"])\n",
    "\n",
    "cleanBU_(geo,\"Hessen\",\"Niedersachsen\")\n",
    "cleanBU_(geo,\"Hessen\",\"Rheinland-Pfalz\")\n",
    "cleanBU_(geo,\"Hessen\",\"Nordrhein-Westfalen\")\n",
    "cleanBU_(geo,\"Bayern\",\"Baden-Württemberg\")\n",
    "cleanBU_(geo,\"Baden-Württemberg\",\"Hessen\")\n",
    "cleanBU_(geo,\"Thüringen\",\"Sachsen\")\n",
    "cleanBU_(geo,\"Schleswig-Holstein\",\"Hamburg\")\n",
    "cleanBU_(geo,\"Mecklenburg-Vorpommern\",\"Niedersachsen\")\n",
    "cleanBU_(geo,\"Mecklenburg-Vorpommern\",\"Brandenburg\")\n",
    "cleanBU_(geo,\"Sachsen-Anhalt\",\"Brandenburg\")\n",
    "\n",
    "geo.plot(alpha=0.5,aspect=1.3,edgecolor='black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = LKS01_loader()[2022]\n",
    "cases = df.loc[df['Schlüssel'] == '------']\n",
    "merged_df = pd.merge(cases,geo,on='Bundesland')\n",
    "merged_df = gpd.GeoDataFrame(merged_df, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = 'RdYlGn_r'\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "merged_df.plot(ax=ax,column='Anzahl erfasste Fälle', legend=True,cmap=cmap,legend_kwds={'label':'Absolute number of crimes'})\n",
    "plot_cities(ax)\n",
    "ax.set(\n",
    "    title=\"Germany 2022: Crimes per federal state\", \n",
    "    aspect=1.4, \n",
    "    facecolor='lightblue',\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cybercrime per federal state over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This might take ~20 seconds\n",
    "data = LKS01_loader()\n",
    "merged_data = []\n",
    "# no \"%-Anteil an allen Fällen\" column available before 2019; compute it manually:\n",
    "print('Loading 2013 - 2022 ...')\n",
    "for year in range(2013,2019):\n",
    "    print(f'Year: {year}', end=\"\\r\", flush=True)\n",
    "    df_year = data[year]\n",
    "    df_year_all = df_year[df_year['Schlüssel'] == '------']['Anzahl erfasste Fälle'].to_numpy()\n",
    "    df_year = df_year.loc[df_year['Schlüssel'] == '897000']\n",
    "    df_year['%-Anteil an allen Fällen'] = df_year['Anzahl erfasste Fälle'].to_numpy() / df_year_all * 100\n",
    "    merged_year = pd.merge(df_year,geo,on='Bundesland')\n",
    "    merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))\n",
    "for year in range(2019,2023):\n",
    "    print(year)\n",
    "    df_year = data[year]\n",
    "    df_year = df_year.loc[df_year['Schlüssel'] == '897000']\n",
    "    merged_year = pd.merge(df_year,geo,on='Bundesland')\n",
    "    merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = min([min(x.loc[:,'%-Anteil an allen Fällen']) for x in merged_data])\n",
    "vmax = max([max(x.loc[:,'%-Anteil an allen Fällen']) for x in merged_data])\n",
    "\n",
    "fig, axs = plt.subplots(3,4,layout='constrained',figsize=(8,7))\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "    if i < len(merged_data):\n",
    "        merged_data[i].plot(ax=ax,column='%-Anteil an allen Fällen', legend=False, cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "        ax.set(aspect=1.4,title=i+2013)\n",
    "    ax.set_axis_off()\n",
    "    if i == len(merged_data):\n",
    "        plot_cbar(ax,vmin,vmax,cmap,'% of all crime')\n",
    "fig.suptitle(\"Germany: Cybercrime per federal state (relative)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huh? Shouldn't 2020 and 2021 be overall higher than other years? (see temporal analysis)\n",
    "\n",
    "Problem: For some reason the fraction of all crime in 2020 and 2021 is not computed wrt. the number of crimes in each federal state, but in all of Germany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_fraction(df_year):\n",
    "    df_year_all = df_year[df_year['Schlüssel'] == '------']['Anzahl erfasste Fälle'].to_numpy()\n",
    "    df_year = df_year.loc[df_year['Schlüssel'] == '897000'].copy()\n",
    "    if '%-Anteil an allen Fällen' in df_year.columns:\n",
    "        df_year.loc[:,'%-Anteil an allen Fällen'] = df_year['Anzahl erfasste Fälle'].to_numpy() / df_year_all * 100\n",
    "    else:\n",
    "       df_year['%-Anteil an allen Fällen'] = df_year['Anzahl erfasste Fälle'].to_numpy() / df_year_all * 100\n",
    "    return pd.merge(df_year,geo,on='Bundesland')\n",
    "\n",
    "data = LKS01_loader()\n",
    "merged_data = []\n",
    "# no \"%-Anteil an allen Fällen\" column available before 2019; compute it manually and fix 2020,2021:\n",
    "print('Loading 2013 - 2022 ...')\n",
    "for year in range(2013,2023):\n",
    "    print(f'Year: {year}', end=\"\\r\", flush=True)\n",
    "    df_year = data[year]\n",
    "    if year in [2019,2022]:\n",
    "        df_year = df_year.loc[df_year['Schlüssel'] == '897000']\n",
    "        merged_year = pd.merge(df_year,geo,on='Bundesland')\n",
    "        merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))\n",
    "    else:\n",
    "        merged_year = add_fraction(df_year)\n",
    "        merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = min([min(x.loc[:,'%-Anteil an allen Fällen']) for x in merged_data])\n",
    "vmax = max([max(x.loc[:,'%-Anteil an allen Fällen']) for x in merged_data])\n",
    "\n",
    "fig, axs = plt.subplots(3,4,layout='constrained',figsize=(8,7))\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "    if i < len(merged_data):\n",
    "        im = merged_data[i].plot(ax=ax,column='%-Anteil an allen Fällen', legend=False, cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "        ax.set(aspect=1.4,title=i+2013)\n",
    "    ax.set_axis_off()\n",
    "    if i == len(merged_data):\n",
    "        plot_cbar(ax,vmin,vmax,cmap,'% of all crime')\n",
    "fig.suptitle(\"Germany: Cybercrime per federal state (relative)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fraud\n",
    "Summenschlüssel:\n",
    "\n",
    "510000: Betrug §§ 263, 263a, 264, 264a, 265, 265a-e StGB\n",
    "\n",
    "897100: Computerbetrug § 263a StGB\n",
    "\n",
    "\"Analog\" = 51000 - 897100\n",
    "\n",
    "\"Digital\" = 897100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = LKS01_loader()\n",
    "merged_data = []\n",
    "# sumkey 897100 did not exist before 2016 (maybe also an explanation why we see sudden increase in cybercrime for that year)\n",
    "print('Loading 2016 - 2022 ...')\n",
    "for year in range(2016,2023):\n",
    "    print(f'Year: {year}', end=\"\\r\", flush=True)\n",
    "    df_year = data[year]\n",
    "    df_year_fraud = df_year.loc[df_year['Schlüssel'] == '510000']\n",
    "    df_year_cfraud = df_year.loc[df_year['Schlüssel'] == '897100']\n",
    "    df_year_ratio = pd.DataFrame({'Bundesland':df_year_fraud['Bundesland'],\n",
    "                                  'Anteil':np.array(df_year_cfraud['Anzahl erfasste Fälle']) /\n",
    "                                  (np.array(df_year_fraud['Anzahl erfasste Fälle']) - np.array(df_year_cfraud['Anzahl erfasste Fälle'])) * 100})\n",
    "    merged_year = pd.merge(df_year_ratio,geo,on='Bundesland')\n",
    "    merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = min([min(x.loc[:,'Anteil']) for x in merged_data])\n",
    "vmax = max([max(x.loc[:,'Anteil']) for x in merged_data])\n",
    "\n",
    "fig, axs = plt.subplots(3,3,layout='constrained',figsize=(6,7))\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "    if i < len(merged_data):\n",
    "        merged_data[i].plot(ax=ax,column='Anteil', legend=False, cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "        ax.set(aspect=1.4,title=i+2016)\n",
    "    ax.set_axis_off()\n",
    "    if i == len(merged_data):\n",
    "        plot_cbar(ax,vmin,vmax,cmap,'% of all fraud')\n",
    "fig.suptitle(\"Germany: Computer fraud\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inhabitants_bu = {'Baden-Württemberg':11124642,\n",
    "                'Bayern':13176989,\n",
    "                'Berlin':3677472,\n",
    "                'Brandenburg':2537868,\n",
    "                'Bremen':676463,\n",
    "                'Hamburg':1853935,\n",
    "                'Hessen':6295017,\n",
    "                'Mecklenburg-Vorpommern':1611160,\n",
    "                'Niedersachsen':8027031,\n",
    "                'Nordrhein-Westfalen':17924591,\n",
    "                'Rheinland-Pfalz':4106485,\n",
    "                'Saarland':982348,\n",
    "                'Sachsen':4043002,\n",
    "                'Sachsen-Anhalt':2169253,\n",
    "                'Schleswig-Holstein':2922005,\n",
    "                'Thüringen':2108863,\n",
    "                'Bundesrepublik Deutschland':84358845}\n",
    "inhabs = np.array([11124642,13176989,3677472,2537868,676463,1853935,6295017,1611160,8027031,17924591,4106485,982348,4043002,2169253,2922005,2108863,84358845])\n",
    "\n",
    "\n",
    "data = LKS01_loader()\n",
    "merged_data = []\n",
    "print('Loading 2013 - 2022 ...')\n",
    "for year in range(2013,2019):\n",
    "    print(f'Year: {year}', end=\"\\r\", flush=True)\n",
    "    df_year = data[year]\n",
    "    cases = df_year.loc[df_year['Schlüssel'] == '------']\n",
    "    merged_year = pd.merge(cases,geo,on='Bundesland')\n",
    "    merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))\n",
    "for year in range(2019,2023):\n",
    "    print(f'Year: {year}', end=\"\\r\", flush=True)\n",
    "    df_year = data[year]\n",
    "    cases = df_year.loc[df_year['Schlüssel'] == '------'].copy() # explicitly copying here takes way longer, but gets rid of the warnings...\n",
    "    cases['HZ nach Zensus'] = cases['Anzahl erfasste Fälle'].to_numpy() / inhabs * 1e5\n",
    "    merged_year = pd.merge(cases,geo,on='Bundesland')\n",
    "    merged_data.append(gpd.GeoDataFrame(merged_year, geometry='geometry'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin = min([min(x.loc[:,'HZ nach Zensus']) for x in merged_data])\n",
    "vmax = max([max(x.loc[:,'HZ nach Zensus']) for x in merged_data])\n",
    "\n",
    "fig, axs = plt.subplots(3,4,layout='constrained',figsize=(8,7))\n",
    "for i,ax in enumerate(axs.flatten()):\n",
    "    if i < len(merged_data):\n",
    "        merged_data[i].plot(ax=ax,column='HZ nach Zensus', legend=False, cmap=cmap,vmin=vmin,vmax=vmax)\n",
    "        ax.set(aspect=1.4,title=i+2013)\n",
    "    ax.set_axis_off()\n",
    "    if i == len(merged_data):\n",
    "        plot_cbar(ax,vmin,vmax,cmap)\n",
    "fig.suptitle(\"Germany: Crimes per Capita and Federal State\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
